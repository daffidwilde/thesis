\chapter{Evolutionary dataset optimisation}

\graphicspath{{chapters/edo/paper/img/}}
\renewcommand{\tikzpath}{chapters/edo/paper/tex/diagrams}
\renewcommand{\algpath}{chapters/edo/paper/tex/algorithms}

\begin{center}
    The research reported in this chapter has led to a
    publication~\cite{Wilde2020:edo} entitled:\\[1em]

    {%
        \bf\itshape{``Evolutionary dataset optimisation: learning algorithm
                    quality through evolution''}
    }

    Available at: \url{https://doi.org/10.1007/s10489-019-01592-4}\\

    Associated data and source code
    archives:~\cite{Wilde2019:edo:data,Wilde2019:edo:code}\\[1em]

    The abstract of the publication is as follows:\\[1em]
\end{center}

In this paper we propose a novel method for learning how algorithms perform.
Classically, algorithms are compared on a finite number of existing (or newly
simulated) benchmark datasets based on some fixed metrics. The algorithm(s) with
the smallest value of this metric are chosen to be the `best performing'. We
offer a new approach to flip this paradigm. We instead aim to gain a richer
picture of the performance of an algorithm by generating artificial data through
genetic evolution, the purpose of which is to create populations of datasets for
which a particular algorithm performs well on a given metric. These datasets can
be studied so as to learn what attributes lead to a particular progression of a
given algorithm.  Following a detailed description of the algorithm as well as a
brief description of an open source implementation, a case study in clustering
is presented. This case study demonstrates the performance and nuances of the
method which we call Evolutionary Dataset Optimisation. In this study, a number
of known properties about preferable datasets for the clustering algorithms
known as \(k\)-means and DBSCAN are realised in the generated datasets.

\myrule%

The differences between this chapter and the publication are an extended
discussion of the motivation behind the Evolutionary Dataset Optimisation method
and its components, as well as a revised case study which concludes the chapter.


\section{Introduction}\label{section:introduction}

This chapter introduces a method known as Evolutionary Dataset Optimisation
(EDO). At its core, EDO is an evolutionary algorithm that acts on datasets to
optimise some real-valued function. While it is possible to perform simple
optimisation tasks with this method, its primary application is in learning the
quality of an algorithm. The concept of an algorithm's quality here refers to
some combination of its robustness, and its strengths and weaknesses.

When developing an algorithm to solve a given problem, questions are raised
about its performance, both objectively and relative to existing methods.
Determining convincing answers to these questions is an inherently difficult
task. However, under the current regime, there is a standard response: take some
benchmark datasets and a common metric (or set thereof) amongst the proposed
method, and its competitors, then assess the methods based on this metric and
deem those with the smallest value to be `best'.

Objectively, there is nothing illicit about comparing methods in this way except
for the semantics of the outcome, i.e.\ outperforming a method on a dataset with
a metric is insufficient evidence to categorise one method as `better' than
another. Each case can be qualified with something along the lines of `Method
\(A\) performs better than Method \(B\) under the given conditions', but there
are concerns about this process that persist beyond linguistic hair-splitting. 

A significant concern presented by this process is in how benchmark examples are
selected; there is no real measure of their reliability other than their
frequent use. Although there do exist benchmark dataset suites that are curated
to be relevant, diverse and comprehensive for some problem domains --- such as
machine learning~\cite{Dua2019,Olson2017} and time series~\cite{UCRArchive2018}
--- it is often the case that a dataset becomes a benchmark for merely being
longstanding and used many times. This title awards the dataset with the
accolades of being reliable and trustworthy. However, this is not guaranteed.

Computer vision is one such domain where these questionable de facto benchmarks
have come to exist out of provenance.~\cite{Prabhu2020} dissects the unethical
and problematic practices used in the creation and aggregation of several
benchmark datasets from computer vision including the renowned \emph{ImageNet}
datasets~\cite{Deng2009}. These practices pose serious questions about the
credibility of the models trained using these benchmarks, both morally and as a
matter of their performance. The exposition highlights questions of consent and
privacy as well as revealing a valid moral quandary given that the social,
cultural and racial biases transferred from these datasets to the models will
then diffuse into systems that are synonymous with life in the age of `Big
Data'.

As an example of the reality of these systemic biases, in 2015, it was made
public that the automatic classifier developed as part of \emph{Google Photos}
had been incorrectly labelling images of Black people as gorillas. Google
publicly apologised and vowed to fix the problem, but since then the only action
taken to mitigate this has been to remove several primates from the set of
labels available to their model~\cite{Simonite2018}.

Leaving computer vision aside,~\cite{Campos2016} raises questions about the
availability and suitability of benchmark datasets in the field of unsupervised
outlier detection. The authors point out that even though systematic approaches
exist for the generation of benchmark datasets, the approaches are not
sufficiently documented to be reproducible, thus rendering them scientifically
moot.

In addition to this, the authors discuss the troubles that come with co-opting
datasets designed for another task (classification in their case) in the absence
of existing benchmarks designed for outlier detection. This practice is
indicative of another issue with this aspect of the current paradigm where
convenience has become a driving force for benchmark selection rather than
merit.

Striving for convenience may well be an issue that stems from the competitive
nature of algorithm design. In order for a method to become `state-of-the-art',
there has to be some comparable evaluation with existing methods. However, this
should not be the end of the line when discussing the quality of any method.
More extensive work is required to understand an algorithm truly and to quantify
its quality, which leads to the other source of concern in the established
process: the methods themselves.

Holding a method to account on a finite number of example datasets ---
regardless of their reliability or diversity --- limits the amount of learning
one can gain about that method. In particular, it limits the learning of the
characteristics which lead to good or bad performance to those attributes
present in the set of example datasets. Another example from computer
vision,~\cite{Torralba2011}, shows that Support Vector Machines (SVMs) --- a
method that is ubiquitous in classification --- fail to perform well when tested
on a dataset containing comparable and broadly equivalent items to the one they
on which they have been trained. So, despite the abundant use of SVMs, even in
the then-`best' image classifier, there is no strong sense of robustness in the
model.

Taking a step back from empirical examples of algorithm evaluation, consider the
space between algorithms and data more generally. To evaluate an algorithm,
i.e.\ a fixed point in the space of algorithms, one maps it to a finite subset
of points in the space of datasets using some metric(s). How that subset is
determined is what has been discussed thus far. The process when travelling in
the opposite direction is not so standardised, but it appears more rigorous.

Suppose that the object of interest was not an algorithm but rather a dataset.
In this case, the objective is to determine a preferable algorithm to complete
some task on the data. There exist many ways of achieving this that appear in a
range of disciplines. However, each takes into account the constraints and
characteristics of the data and the context of the research problem. These
methods are often equivalent to asking questions of the data and can include the
use of diagnostic tests. For instance, in the case of clustering, if the data
displayed an indeterminate number of non-convex blobs, then one could recommend
that an appropriate clustering algorithm would be DBSCAN~\cite{Ester1996}.
Otherwise, for scalability, \(k\)-means may be chosen~\cite{Wu2009,Zhao2009}.

The EDO method belongs to a new paradigm that aims to flip the process described
here by allowing the data itself to be unfixed. EDO achieves this fluidity by
generating data for which the algorithm of interest performs well (or better
than some other) through the use of an evolutionary algorithm. The purpose of
doing so is not to simply create a bank of useful datasets but rather to allow
for the subsequent studying of those datasets. Undergoing this study describes
the attributes and characteristics which lead to the success (or failure) of the
algorithm, giving a broader understanding of the algorithm on the whole.
Figure~\ref{fig:paradigm} provides a diagram of this framework; on the right:
the current path for selecting some algorithm(s) based on their validity and
performance for a given dataset; on the left: the proposed flip to better
understand the space in which `good' datasets exist for an algorithm.

\inputtikz{paradigm}{%
    A diagram of the current and proposed paradigms for algorithm evaluation
}

The method described here is just one element of this new paradigm that utilises
evolution. Evolutionary algorithms (EAs) have been applied successfully to solve
a wide array of problems --- particularly where the complexity of the problem or
its domain is significant. These methods are highly adaptive, and their
population-based construction (displayed in Figure~\ref{fig:flowchart}) allows
for the efficient solving of problems that are otherwise beyond the scope of
traditional search and optimisation methods. An EA approach has been chosen here
as they are simple in design, yet their capabilities encompass the difficulties
of the flipped paradigm set out above.

\inputtikz{flowchart}{%
    A general schematic for an evolutionary algorithm
}

The use of EAs to generate artificial data is not a new concept, however.
Applications of EAs to data generation have included developing methods for the
automated testing of software~\cite{Koleejan2015,Michael2001,Sharifipour2018}
and the synthesis of existing or confidential data~\cite{Chen2016}. Such methods
also have a long history in the parameter optimisation of algorithms, and
recently in the automated design of convolutional neural network (CNN)
architecture~\cite{Suganuma2017,Sun2018}.

Other methods for the generation or synthesis of artificial data are numerous
and range from simple concepts such as simulated annealing~\cite{Matejka2017} to
swarm-based learning techniques~\cite{Abualigah2018b} or generative adversarial
networks (GANs)~\cite{Goodfellow2014}. The unconstrained learning style of
methods like CNNs and GANs aligns with those in the proposed paradigm, and with
EDO in particular. By allowing the EA to explore and learn about the search
space in an organic way, less-prejudiced insight can be established that is not
necessarily reliant on any particular framework or agenda.

Note that there is no necessary restriction on the search space to be of a fixed
dimension or data type such as the method described in~\cite{Chen2016}. The
shape of a dataset is considered a part of the search space itself that can be
traversed through the evolutionary algorithm.

The remainder of this chapter is structured as follows:
\begin{itemize}
    \item Section 2 describes the parameterisation, structure and components of
        the EDO method.
    \item Section 3 contains a case study examining the success and failure of
        \(k\)-means clustering using EDO. Included also is a comparison between
        \(k\)-means and another clustering algorithm DBSCAN.\
    \item Section 4 summarises the chapter.
\end{itemize}


\section{The evolutionary algorithm}\label{section:algorithm}

This section presents the details of the EDO algorithm. As stated previously,
the EDO method is an EA. The EA follows a typical schema with the addition of
some features that align with the overall objective of artificial data
generation. With that, there are a number of parameters that are passed to EDO;\
the typical parameters of an evolutionary algorithm are a fitness function,
\(f\), which maps from an individual to a real number, as well as a population
size, \(N\), a maximum number of iterations, \(M\), a selection parameter,
\(b\), and a mutation probability, \(p_m\). In addition to these, EDO takes the
following parameters:
\begin{itemize}
    \item A set of probability distribution families, \(\mathcal{P}\). Each
        family in this set has some parameter limits which form a part of the
        overall search space. For instance, the family of normal distributions,
        denoted by \(N(\mu, \sigma^2)\), would have limits on values for the
        mean, \(\mu\), and the standard deviation, \(\sigma\).
    \item A maximum number of `subtypes' for each family in \(\mathcal{P}\). A
        subtype is an independent copy of the family distribution that
        progresses separately from the other subtypes in that family. These are
        the actual distribution objects which are traversed in the optimisation
        and that are passed to the individuals.
    \item A probability vector to sample distributions from \(\mathcal{P}\),
        \(w = \left(w_1, \ldots, w_{|\mathcal{P}|}\right)\).
    \item Limits on the number of rows an individual dataset can have,
        \[
            R \in \left\{%
                (r_{\min}, r_{\max}) \in \mathbb{N}^2~|~r_{\min} \leq r_{\max}
            \right\}
        \]
    \item Limits on the number of columns a dataset can have,
        \[
            C := \left(C_1, \ldots, C_{|\mathcal{P}|}\right)
            \text{ where }
            C_j \in \left\{ (c_{\min}, c_{\max}) \in {%
                \left(\mathbb{N}\cup\{\infty\}\right)
            }^2~|~c_{\min} \leq c_{\max}\right\}
        \]
        for each \(j = 1, \ldots, |\mathcal{P}|\). That is, \(C\) defines the
        minimum and maximum number of columns a dataset may have from each
        distribution in \(\mathcal{P}\).
    \item A second selection parameter, \(l \in [0, 1]\), to allow for a
        small proportion of `lucky' individuals to be carried forward.
    \item A shrink factor, \(s \in [0, 1]\), defining the relative size of a
        component of the search space to be retained after adjustment.
\end{itemize}

This chapter discusses the components and mechanisms of the EDO method in a
largely mathematical manner. However, a Python package,
\href{https://github.com/daffidwilde/edo}{\mintinline{python}{edo}}, that
implements the EDO algorithm is used to demonstrate its practical use and
particular technical aspects of the method. This implementation is built on the
scientific Python stack~\cite{pandas,numpy} and has been developed to be
consistent with the current best practices of open source software
development~\cite{Jimenez2017} so that it is modular, automatically tested and
fully documented. It is freely available online under the MIT
licence~\cite{edo-project}.

Algorithm~\ref{alg:edo} provides a high-level description of the EDO algorithm
that presents its general structure. More detailed discussion is provided in
this section along with relevant examples, diagrams and algorithm statements for
the abstract processes mentioned there: the creation of individuals, the
evolutionary operators and the `shrinkage' process.

\inputalg{edo}
\inputalg{new_population}

Note that there are no defined processes for how to stop the
algorithm or adjust the mutation probability, \(p_m\). This generality is
deliberate and is down to their relevance in a particular use case. Some
examples include:
\begin{itemize}
    \item Regular decreasing in mutation probability across the available
        attributes~\cite{Kuehn2013}.
    \item Stopping when no improvement in the best fitness is found within some
        \(K\) consecutive iterations~\cite{Leung2001}.
    \item Utilising global behaviours in fitness to indicate a stopping
        point~\cite{Marti2016}.
\end{itemize}


\subsection{Individuals}

Evolutionary algorithms operate in an iterative process. At each iteration, the
EA acts on a population (generation) of individuals. Each individual corresponds
to a solution to the problem in question according to some representation or
encoding. In a genetic algorithm, an individual is a solution encoded as a bit
string of typically fixed length and is treated as a chromosome-like object to
be manipulated.

In EDO, individuals are represented primarily as the dataset that defines them,
without an encoding. This is because the objective of EDO is to generate
datasets and explore the space in which datasets exist. Therefore, to design
meaningful operators on these solutions, this form is preserved. Creation is one
such operator that is governed by this representation.
Figure~\ref{fig:individual} shows this process diagrammatically and
Algorithm~\ref{alg:individual} provides a simplified statement of the
individual-creation process.

In addition to the dataset, an individual is represented by a list of
probability distributions. These distributions are created using the elements
of~\(\mathcal{P}\) and correspond to the columns of the dataset. This list is
referred to as the individual's `metadata'. The metadata acts as a set of
instructions for sampling new values for the columns (as in mutation). Also, the
metadata is a record of how that column was created.

However, one should not assume that the columns are a reliable representative of
the distribution associated with them or vice versa; this is particularly true
of `shorter' datasets with only a few rows, whereas confidence in the pair could
be given more liberally for `longer' datasets with a more significant number of
rows. In any case, appropriate methods of analysis should be employed before
formal conclusions are made about these relationships.

\inputtikz{individual}{%
    An example of how an individual is first created
}
\inputalg{individual}


\subsection{Selection}

The selection operator describes the process by which individuals are chosen
from the current population to generate the next. Almost always, the fitness of
an individual determines the likelihood of their selection to be a parent. By
selecting individuals in this way, the hope is for the preservation of some
favourable qualities (thus improving the population). Also, to encourage some
homogeneity within future generations~\cite{Back1994}.

\inputtikz{selection}{%
    The selection process with the inclusion of some lucky individuals
}
\inputalg{selection}

A modified truncation selection method is used in EDO, as is illustrated in
Figure~\ref{fig:selection}. Truncation is perhaps the simplest selection method
wherein a fixed number, \(n_b = \left\lceil b N\right\rceil\), of the fittest
individuals in a population are taken forward and used as the `parents' of the
next generation. Note that this means that an individual could potentially be
present throughout the entirety of the algorithm.

Despite its efficiency as a selection operator, truncation selection can lead to
premature convergence at local optima~\cite{Jebari2013,Motoki2002}. EDO provides
an optional modification to counteract this where, after the best individuals
have been chosen, some number, \(n_l = \left\lceil l N\right\rceil\), of the
remaining individuals can be selected uniformly to be carried forward. The
purpose of taking forward a small number of `lucky' individuals is to introduce
some diversity in the genetic pool of the parent individuals, thus adding to the
exploration of the search space.

After the parents have been selected, there are two adjustments made to the
current search space. The first is that the subtypes for each family in
\(\mathcal{P}\) are updated to include only those present in the parents. The
second adjustment is a process which acts on the distribution parameter limits
for each subtype in \(\mathcal{P}\) and takes place once the new generation has
been created. This adjustment gives the ability to `shrink' the search space
about the region observed in a given population. This method is based on a power
law described in~\cite{Amirjanov2016} that relies on a shrink factor, \(s\). At
each iteration, \(t\), every distribution subtype which is present in the
parents has its parameter's limits, \(\left(l_t, u_t\right)\), adjusted. This
adjustment is such that the new limits, \(\left(l_{t+1}, u_{t+1}\right)\) are
centred about the mean observed value, \(\mu\), for that parameter:
\begin{align}
    \label{eq:shrinking_lower}
    l_{t+1}&= \max \left\{l_t, \ \mu - \frac{1}{2} (u_t - l_t) s^t\right\}\\
    \label{eq:shrinking_upper}
    u_{t+1}&= \min \left\{u_t, \ \mu + \frac{1}{2} (u_t - l_t) s^t\right\}
\end{align}

The shrinking process is given explicitly in
Algorithm~\ref{alg:shrinking}. Note that the behaviour of this process can
produce reductive results where very early convergence is achieved at the cost
of extensive exploration and is considered to be decidedly optional.

\inputalg{shrinking}


\subsection{Crossover}

Crossover is the operation of combining two individuals in order to create a new
individual (or individuals). It is also the opportunity to have the favourable
qualities preserved through selection interact with one another in potentially
new ways. The term `crossover' originates from its application in genetic
algorithms where it is quite literal. In genetic algorithms, two bit-strings are
crossed at a point to create two new bit strings.

Another popular method is uniform crossover, where the components of two parents
are sampled uniformly to create a new individual. This method is efficient and
is effectual in combining individuals to preserve homogeneity in both bit string
and matrix representations~\cite{Chen2018,Semenkin2012}. EDO makes use of a form
of uniform crossover that has been adapted to support the representation of
individuals in the EA. Put simply: a new offspring is created by uniformly
sampling each of its components (i.e.\ dimensions and columns) from a set of two
`parent' individuals, as depicted in Figure~\ref{fig:crossover} and described in
Algorithm~\ref{alg:crossover}.

\inputtikz{crossover}{%
    The crossover process between two individuals with different dimensions
}

Observe that there is no requirement on the dimensions of the parents to be of
similar or equal shapes. This laxness is allowed because the proposed method
allows for individuals of different shapes, and their combination can be
reconciled because of how individuals are represented. Where there is an
incongruence in the lengths of the two parents, missing values may appear in a
shorter column that has been sampled. New values are sampled from the
probability distribution associated with that column to fill in these gaps.
Conversely, surplus values are trimmed from the bottom of all longer columns.


\inputalg{crossover}

\subsection{Mutation}\label{subsection:mutation}

The mutation operator is used in EAs to maintain a level of variety in a
population. This operator effectively forces the algorithm to explore more of
the search space at each generation. It is typical of mutation operators to
affect all aspects of an individual. In genetic algorithms, this is as simple as
running along a bit string and swapping a zero to a one (or one to zero). Under
the EDO framework, the mutation process manipulates the phenotype of an
individual by potentially modifying its dimensions and the entries of its
dataset. Figure~\ref{fig:mutation} gives a diagrammatic description of this
process, and a formal statement of the algorithm is described in
Algorithm~\ref{alg:mutation}.

In the publication that initially presented EDO, this process included a
penultimate stage where the metadata of an individual could be mutated. This
manipulation sampled new parameter values for each distribution in the metadata
with the mutation probability, \(p_m\). Following subsequent testing, and in the
process of documenting the Python library, it was decided that allowing for this
kind of mutation made for confusing results. In particular, studying the
resultant individuals became more complicated when individuals retained values
in their columns that were now beyond any reasonable bounds of the associated
distribution, for instance. Since removing this stage of the process, no
noticeable impact has been identified on the ability of the EA to traverse the
search space compared with its inclusion.

\inputtikz{mutation}{The mutation process}

Each of the potential mutations occurs with the same probability \(p_m\).
However, how the columns are maintained assure that (assuming appropriate
choices for \(f\) and \(\mathcal{P}\)) even multiple mutations in the dataset
will only result in some incremental change in the individual's fitness relative
to, say, a completely new individual.

\inputalg{mutation}


\section{A case study in clustering}\label{section:examples}

The following case study contains three examples that act as a form of
validation for EDO. These examples also highlight some of the nuances in its
use. This case study uses the proposed method to reproduce some known results
about the clustering of data in the absence of any external forces and examines
how clustering algorithms are typically evaluated. In particular, the focus will
be on the well-known \(k\)-means (Lloyd's) algorithm. Clustering has been chosen
as it is a well-understood problem that is easily accessible --- most notably
when restricted to two dimensions.

\subsection{Inertia and \(k\)-means clustering}

The \(k\)-means algorithm is an iterative, centroid-based method that aims to
minimise the `inertia' of the current partition, \(Z = \left\{Z_1, \ldots,
Z_k\right\}\), of some dataset \(X\):
\begin{equation}
    I(Z, X) := \frac{1}{|X|} \sum_{j=1}^{k} \sum_{x \in Z_j} {d(x, z_j)}^2
    \label{eq:inertia}
\end{equation}

A full statement of the algorithm to minimise~\eqref{eq:inertia} is given in
Algorithm~\ref{alg:kmeans}.

\balg%
\KwIn{a dataset \(X\), a number of centroids \(k\), a distance metric \(d\)}
\KwOut{a partition of \(X\) into \(k\) parts, \(Z\)}

\Begin{%
    select \(k\) initial centroids, \(z_1, \ldots, z_k \in X\)\;
    \While{any point changes cluster or some stopping criterion is not met}{%
        assign each point, \(x \in X\), to cluster \(Z_{j^*}\) where:
        \[
            j^* = \argmin_{j = 1, \ldots, k} \left\{%
                {d\left(x, z_j\right)}^2
            \right\}
        \]\;
        recalculate all centroids by taking the intra-cluster mean:
        \[
            z_j = \frac{1}{|Z_j|} \sum_{x \in Z_j} x
        \]
    }
}
\caption{\(k\)-means (Lloyd's algorithm)}\label{alg:kmeans}
\ealg%

As this inertia function is the objective of the \(k\)-means algorithm, it is
often used for evaluating the quality of the final clustering it produces.
However, since it is not a normalised measure, other metrics are often used.
Many of these metrics --- such as accuracy, recall and precision --- are used
under the assumption that clustering is some sort of unsupervised classification
task which is fundamentally wrong. Therefore, as a starting point, the first
example uses inertia as the fitness function in EDO.\ That is, EDO is used to
find datasets that minimise the final inertia found by \(k\)-means clustering.

For visualisation purposes, these examples will restrict EDO to datasets that
are two-dimensional, i.e. \(C = ((2, 2))\). Then, for simplicity, each dataset
will be clustered into three parts, i.e. \(k = 3\), and have its columns formed
from uniform distributions, denoted by \(U\), enclosed by the unit interval.
Thus, the search space is the unit square, and the only element of
\(\mathcal{P}\) is:
\begin{equation}\label{eq:uniform}
    \mathcal{U} := \left\{U(a, b)~|~a, b \in [0, 1]\right\}
\end{equation}


The remaining parameters are as follows: \(N=100\), \(R=(50,100)\), \(M=100\),
\(b=0.1\), \(l=0\), \(p_m=0.01\), and shrinkage is excluded. This set of
parameters has been adapted from that used in~\cite{Wilde2020:edo}. The changes
are: omitting the trivial case where the number of rows equals \(k\); shortening
the run time to reduce computational resources, and because the EA produces as
useful results, indicating the identification of a local optimum; and, finally,
increasing the selective pressure (by reducing \(b\)) to mitigate the effect of
noise in later generations.

In addition to these parameter changes, the fitness function has been altered.
In this study, every individual is scaled using a min-max scaler so their values
are in the interval \(\left[0, 1\right]\). This makes the value of limits
in~\eqref{eq:uniform} arbitrary and eliminates the pinching effect observed
in~\cite{Wilde2020:edo} where well-performing individuals were
disproportionately compact. Following this scaling, the number of
initialisations for the \(k\)-means algorithm has been increased from ten to 50
so that there is greater confidence in the fitness score.

The examples in this study make use of a command-line tool,
\href{https://github.com/daffidwilde/edolab}{\mintinline{python}{edolab}}, for
running experiments with the library. This tool allows for a lot of otherwise
repeated code to be replaced by a simple `experiment' script.
Snippet~\ref{snp:inertia} shows the experiment script used for this example, and
Snippet~\ref{snp:edolab} shows how to use that script with the command-line
tool. Other than the fitness function definition, this script is identical to
that of every example in this section.

\begin{listing}
\begin{sourcepy}
""" /path/to/experiments/kmeans_inertia.py """

from edo.distributions import Uniform
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler


def fitness(individual, max_seed=5):
    """ Return the lowest final inertia of k-means on the individual
    across the given number of trials with k=3. """

    data = MinMaxScaler().fit_transform(individual.dataframe, copy=True)

    inertias = []
    for seed in range(max_seeds):
        km = KMeans(n_clusters=3, random_state=seed).fit(data)
        inertias.append(km.inertia_)

    return min(inertias)


size = 100
row_limits = [50, 100]
col_limits = [2, 2]
max_iter = 100
best_prop = 0.1
lucky_prop = 0
mutation_prob = 0.01

Uniform.param_limits["bounds"] = [0, 1]
distributions = [Uniform]
\end{sourcepy}
\caption{%
    An abridged version of the experiment configuration script used in the first
    example
}\label{snp:inertia}
\end{listing}

\begin{listing}
\begin{usagesh}
> edolab run --seeds=10 --cores=4 /path/to/experiments/kmeans_inertia.py
> edolab summarise --tarball /path/to/experiments/kmeans_inertia.py
\end{usagesh}
\caption{Example usage of the \mintinline{python}{edolab} command-line tool}
\label{snp:edolab}
\end{listing}

Once the EDO algorithm has terminated, a body of datasets, and information about
those datasets, is recorded. This output is referred to as a `history'.
Figure~\ref{fig:inertia_progression} shows the progression of the fitness
function (inertia) and the number of rows at 10 generation intervals across the
history generated with the parameters defined above. There is a steep learning
curve here; within the first ten generations the population fitness gains
substantially, and although there is constant improvement to the median and best
fitness scores, the pace slows over the remaining generations.

The same quick convergence is evident in the number of rows where it is apparent
that there is a preference for datasets with fewer rows. Wanting fewer rows is
expected given that inertia is the sum of the mean error from each cluster
centre. Then, with \(k\) fixed a priori, a quick way of reducing this mean error
is to reduce the number of points in each cluster; doing this reduces the number
of terms in the second summation of~\eqref{eq:inertia}.~\cite{Wilde2020:edo}
included the case where \(r_{min}=3\) in this example, and the EA successfully
identified it before promptly getting stuck there.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_inertia_fitness.pdf}
        \label{fig:kmeans_inertia_fitness}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_inertia_nrows.pdf}
        \label{fig:kmeans_inertia_nrows}
    \end{subfigure}
    \caption{%
        Progressions for final inertia and the number of rows
    }\label{fig:inertia_progression}
\end{figure}

Aside from these progressions, a more focused look may be taken at the generated
datasets. Figure~\ref{fig:kmeans_inertia_inds} shows the individuals with a
fitness closest to the lowest, median and highest values across the entire
history after min-max scaling. These individuals correspond to the best-,
most-middling- and worst-performing individuals in said history. As may have
been expected, the worst individuals are random clouds that show no clear
clusters. However, there are some patterns in the better-performing individuals.

In the opening example of~\cite{Wilde2020:edo}, the best and median individuals
showed clusters that were all essentially the same point. That kind of behaviour
was exhibited, in part, because it was allowed; the fitness function did nothing
to penalise the proximity of the inter-cluster means. The need for this penalty
does not exist in the current fitness function because of the scaling step
before the application of the \(k\)-means algorithm. By scaling the dataset, the
entire unit square must be used by every individual, thus reducing the effect of
that otherwise dominant behaviour.

Although having clusters that are exceptionally compact provides optimal values
of \(I\), it leaves little else to be learnt. In this case, it is still clear
that there is a preference for tight clusters, but also it appears that
well-performing datasets have columns with a strong positive correlation.
Having such a relationship may seem irrelevant to the success of \(k\)-means but
in doing so, the dataset becomes one-dimensional. Removing a dimension reduces
the search space of the algorithm considerably, and makes it easier for the
\(k\)-means algorithm to achieve its true goal of finding the centroidal Voronoi
tessellation of a dataset~\cite{Du2006}. When restricted to a single dimension
and with \(k = 3\), the optimal tessellation is equivalent to finding the
tertiles of a set of numbers, and when \(k = 2\) this is the same as finding the
median.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\imgwidth]{kmeans_inertia_inds.pdf}
    \caption{%
        Representative individuals from EDO trials with inertia
    }\label{fig:kmeans_inertia_inds}
\end{figure}

So, this leaves the question: is there anything else to be learnt? The answer
is, ``probably''. From here, the parameters passed to EDO may be changed, or the
fitness function could be altered. In the example above, the presence of strong
positive correlations stood out. 

\subsection{Discounted silhouette coefficients}

However, the fitness function may be addressed still, and more extensive
studying may be done. Indeed, the final inertia could be considered a flawed or
fragile fitness function if it is supposed to evaluate the efficacy of the
\(k\)-means algorithm. Incorporating the inter-cluster spread to the fitness
of an individual dataset would reduce this observed compaction. For instance,
the silhouette coefficient is a metric used to evaluate the appropriateness of a
clustering to a dataset and does precisely that. The silhouette coefficient of a
clustering of a dataset is given by the mean of the silhouette value,
\(S(x)\), of each point \(x \in Z_j\) in each cluster:
\begin{equation}
    \begin{gathered}
        A(x) := \frac{1}{|Z_j| - 1} \sum_{y \in Z_j \setminus \{x\}} d(x, y),
        \\
        B(x) := \min_{k \neq j} \frac{1}{|Z_k|} \sum_{w \in Z_k} d(x, w),
        \\
        S(x) :=
            \begin{cases}
                \frac{B(x) - A(x)}{\max\left\{A(x), B(x)\right\}}
                &\quad \text{if } |Z_j| > 1\\
                0 &\quad \text{otherwise}
            \end{cases}
    \end{gathered}\label{eq:silhouette}
\end{equation}\\

The optimisation of the silhouette coefficient is analogous to finding a dataset
which increases both the intra-cluster cohesion (the inverse of \(A\)) and
inter-cluster separation (\(B\)). Hence, the objective of minimising inertia is
addressed by maximising cohesion. Meanwhile, the additional desire to spread out
the clusters is considered by maximising separation.

Repeating the trials with the same parameters as with inertia, the silhouette
fitness function yields the results summarised in
Figures~\ref{fig:small-silhouette}~and~\ref{fig:large-silhouette}. Irrespective
of row limits, the datasets produced show increased separation from one another
whilst maintaining low values in the final inertia of the clustering as shown in
Figure~\ref{fig:silhouette-inds}. Again, the form of the individual clusters is
much the same. The low values of inertia correspond to tight clusters, and the
tightest clusters are those with a minimal number of points, i.e.\ a single
point. As with the previous example, albeit at a much slower rate, the
preferable individuals are those leading toward this case. That this gradual
reduction in the dimension of the individuals occurs despite adjusting the
fitness function and considering the space which excludes the trivial case
bolsters the claim that the base case is also optimal.

At this point, it should be noted that, due to the nature of the implementation,
any individual from any generation may be retrieved and studied should the final
results be too concentrated on any given case. The summary provided here is one
particular way of studying the body of datasets generated with this method and
this transparency in the history and progression of the proposed method is
something that sets it apart from other methods such as GANs which have a
reputation of providing so-called `black box' solutions.

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_silhouette_fitness.pdf}
        \label{fig:kmeans_silhouette_fitness}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_silhouette_nrows.pdf}
        \label{fig:kmeans_silhouette_nrows}
    \end{subfigure}
    \caption{%
        Progressions for silhouette and number of rows
    }\label{fig:silhouette_progression}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\imgwidth]{kmeans_silhouette_inds.pdf}
    \caption{%
        Representative individuals from EDO trials with silhouette
    }\label{fig:kmeans_silhouette_inds}
\end{figure}

\subsection{Comparison with DBSCAN}\label{subsec:dbscan}

The extent of the capabilities EDO holds as a tool to better understand an
algorithm are especially apparent when comparing an algorithm against another
(or set of others) simultaneously. This is done by utilising the freedom of
choice in a fitness function for EDO.\ Consider two algorithms, \(A\) and \(B\),
and some common metric between them, \(g\). Then their similarities and
contrasts can be explored by considering the differences in this metric on the
two algorithms. In terms of EDO, this means using \(f = g_A - g_B\), \(f = g_B -
g_A\) or \(f = \left| g_B - g_A \right|\) as the fitness function. By doing so,
pitfalls, edge cases or fundamental conditions for the method may be
highlighted. Overall, this process allows the researcher to more deeply learn
about the method of interest beyond the traditional method of literature
comparison on a particular example.

Consider the following use case with another clustering algorithm of a different
form, Density Based Spatial Clustering of Applications with Noise (DBSCAN). In
this particular case, the objective is to find datasets for which the method of
interest, \(k\)-means, outperforms its alternative, DBSCAN.\ Here there is no
concept of inertia as DBSCAN is density-based and is able to identify
outliers~\cite{Ester1996}. As such, a valid metric must be chosen. One such
metric is the silhouette score as defined in~(\ref{eq:silhouette}).

In this case, however, an adjustment to the fitness function must be made so as
to accommodate for the condition of the silhouette coefficient that there must
be more than one cluster present. Let \(S_k (X)\) and \(S_D (X)\) denote the
silhouette coefficients of the clustering found by \(k\)-means and DBSCAN
respectively. Then the fitness function is defined to be:
\begin{equation}
    f(X) =
        \begin{cases}
            S_D (X) - S_k (X), &\quad \text{%
                \begin{tabular}{l}%
                    if DBSCAN identifies two or
                    \\
                    more clusters (inc.\ noise)
                \end{tabular}
            }\\
            \infty &\quad \ \ \text{otherwise.}
        \end{cases}\label{eq:dbscan-fitness}
\end{equation}

There are several remarks to be made here. First, note the order of the
subtraction here as EDO minimises fitness functions by default. Also, \(f\)
takes values in the range \([-2, 2]\) where \(-2\) is the best, i.e.\ \(S_D(X) =
-1\) and \(S_k(X) = 1\). Likewise, 2 is the worst score. Finally, the silhouette
coefficient requires at least two clusters to be present and so if DBSCAN
identifies a single cluster then that individual will be penalised heavily under
this fitness function when, in fact, that clustering may be of high quality. As
such, this fitness function may require adjustment.

It must also be acknowledged that \(k\)-means and DBSCAN share no common
parameters and so direct comparison is more difficult. For the purposes of this
example, only one set of parameters is used but a thorough investigation should
include a parameter sweep in similar, real-world use cases. The parameters being
used are \(k~=~3\) for \(k\)-means, and \(\epsilon~=~0.1,\ MinPoints~=~5\) for
DBSCAN.\ This set was chosen following informal experimentation using the Python
library Scikit-learn~\cite{scikit} to find comparable parameters in the given
search space defined by the EDO parameters used previously with
\(R~=~(50,100)\).

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_preferable_fitness.pdf}
        \label{fig:kmeans_preferable_fitness}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_preferable_nrows.pdf}
        \label{fig:kmeans_preferable_nrows}
    \end{subfigure}
    \caption{%
        Progressions for the (\(k\)-means preferable) difference in silhouette
        and dimension
    }\label{fig:dbscan-silhouette}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_preferable_kmeans_inds.pdf}
        \caption{%
            clustered by \(k\)-means
        }\label{fig:kmeans_preferable_kmeans_inds}
    \end{subfigure}

    \vspace{1em}
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{kmeans_preferable_dbscan_inds.pdf}
        \caption{clustered by DBSCAN}\label{fig:kmeans_preferable_dbscan_inds}
    \end{subfigure}
    \caption{%
        Representative individuals from the \(k\)-means-preferable trials
    }\label{fig:dbscan-inds}
\end{figure}

Figure~\ref{fig:dbscan-silhouette} shows a summary of the progression of EDO for
this use case. As with the previous examples where \(R~=~(50, 100)\), the
variation in the population fitness is unstable but there is a clear trend of
improvement in the best individual over the course of the run. There is also a
convergence seen in the number of rows a dataset has. The resting dimension
varied across the trials conducted in this work but none exhibited a dramatic
shift toward the lower limit of 50 rows as with previous examples. This is
suggestive of a more competitive environment for individuals where slight
changes to an individual can drastically alter their fitness.

The effect of such changes can be seen in Figure~\ref{fig:dbscan-inds} where
representative individuals are shown for this example. In addition to the
scattering of the clusters and their centres, the concave and convex hulls of
each cluster are illustrated by shading and outline respectively. Here, the best
performing individual, when clustered by \(k\)-means, shows three clear and
nicely separated clusters. Note that they are not so tightly packed; again, this
suggests that the route to an optimal individual is less clearly defined. In
contrast, when the same dataset is clustered by DBSCAN a single cluster is found
with a single noise point held within the convex hull of the cluster, i.e.\
there are overlapping clusters (since noise points form a single cluster).
Hence, along with the fact that the larger cluster is widely spread, it follows
that the clustering has a relatively small, negative silhouette coefficient.

Another point of interest here is the convexity of the clusters. A known
condition for the success of \(k\)-means is that the presented clusters are of
roughly equal size and are convex. This is due to the overall objective being to
approximate the centroidal Voronoi tessellation~\cite{Du2006}. Without this
condition, up to the correct choice of \(k\), the algorithm will fail to produce
adequate results for either inertia or silhouette. DBSCAN, on the other hand,
does not have this condition and is able to detect non-convex clusters so long
as they are dense enough. Figure~\ref{fig:dbscan-inds} shows the clustering
found by each method and the respective convex and concave hulls of the clusters
found. The `concave hull' of a cluster is taken to be the \(\alpha\)-shape of
the cluster's data points~\cite{Edelsbrunner1983} where \(\alpha\) is determined
to be the smallest value such that all the points in the cluster are contained
in a single polygon. The convexity of cluster \(Z_j\), denoted
\(\mathcal{C}_j\), is then determined to be the ratio of the area of its concave
hull, \(H_c\), to the area of its convex hull, \(H_v\)~\cite{Sonka1993}:
\begin{equation}
    \mathcal{C}_j :=
    \frac{\text{area}\left(H_c\right)}{\text{area}\left(H_v\right)}
\end{equation}

With this definition, it should be clear that a perfectly convex cluster, such
as a single point or line, would have \(\mathcal{C}_j = 1\).

It can be seen that the convexity of the clustering found by \(k\)-means appears
to be higher than that by DBSCAN.\ This was apparent across all trials conducted
in this work and indicates that the condition for convex clusters is being
sought out during the optimisation process. Meanwhile, however, it is not clear
whether the performance of DBSCAN falls owing to its parameters or the method
itself. This is a point where parameter sweeping would prove most useful to
determine a crossing point for these two driving forces.

Now, to add to the discussion above, the inverse optimisation should be
considered. That is, using the same parameters, the datasets for which DBSCAN
outperforms \(k\)-means with respect to the silhouette coefficient are to be
investigated. This is equivalent to using \(-f\) as the fitness function
except with the same penalty of \(\infty\) for the case set out
in~(\ref{eq:dbscan-fitness}).

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{dbscan_preferable_fitness.pdf}
        \label{fig:dbscan_preferable_fitness}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{dbscan_preferable_nrows.pdf}
        \label{fig:dbscan_preferable_nrows}
    \end{subfigure}
    \caption{%
        Progressions for the (DBSCAN-preferable) difference in silhouette and
        dimension
    }\label{fig:negative-prog}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \centering
        \includegraphics[width=\linewidth]{dbscan_preferable_kmeans_inds.pdf}
        \caption{%
            clustered by \(k\)-means
        }\label{fig:dbscan_preferable_kmeans_inds}
    \end{subfigure}

    \vspace{1em}
    \begin{subfigure}{\imgwidth}
        \centering
        \includegraphics[width=\linewidth]{dbscan_preferable_dbscan_inds.pdf}
        \caption{clustered by DBSCAN}\label{fig:dbscan_preferable_dbscan_inds}
    \end{subfigure}
    \caption{%
        Representative individuals from the DBSCAN-preferable trials
    }\label{fig:negative-inds}
\end{figure}

Figures~\ref{fig:negative-prog}~and~\ref{fig:negative-inds} show the same
summary as above with the revised fitness function. Inspecting the former, it is
seen that the best fitness found is worse than with the previous example. This,
in part, is due to the fact that \(k\)-means cannot find a clustering with
negative values as no clusters may overlap. It can, however, produce results
with small silhouette scores where the clusters are tightly packed. Hence, the
best fitness score is now \(-1\) whereas the worst is 2, still.

Note in the first two frames of Figure~\ref{fig:neg-inds-k} how \(k\)-means is
forced to split what is evidently a single cluster in two whereas DBSCAN is able
to identify the single cluster and the outlying noise
(Figure~\ref{fig:neg-inds-d}). The proximity of these clusters has then dragged
the silhouette score down for \(k\)-means. Referring to
Figure~\ref{fig:neg-inds-d}, this kind of behaviour is certainly preferable for
DBSCAN under these parameters: the beginning individuals are likely random
clouds (as seen in the rightmost two frames of the figure) and the simplest step
toward a fit dataset is one that maintains that vaguely dense body with minimal
noise points far from it.

As has already been stated, the software implementation of the EDO method has
been produced in line with the best practices of open source software
development and reproducible research. In aid of this, all the source code used
in these examples (including to create the figures) has been archived under the
DOI \href{https://doi.org/10.5281/zenodo.3492236}{10.5281/zenodo.3492236}.
Likewise, all the data produced to support this case study have been archived
under the DOI
\href{https://doi.org/10.5281/zenodo.3492228}{10.5281/zenodo.3492228}.


\section{Conclusion}

In this paper we have introduced a novel approach to understanding the quality
of an algorithm by exploring the space in which their well-performing datasets
exist. Following a detailed explanation of its internal mechanisms, a case study
in \(k\)-means clustering was offered as validation for the proposed method.
The method was able to reveal some known results without prior knowledge when
investigating \(k\)-means in several scenarios, and again when comparing
\(k\)-means and another leading clustering method, DBSCAN.\

The method itself utilises biological operators to traverse a potentially broad
region of the space of all possible datasets. This is done in an organic way
with a minimal external framework attached. The generative nature of the
proposed method also provides transparency and richness to the solution when
compared to other contemporary techniques for artificial data generation as the
entire history of individuals is preserved. While other search and optimisation
methods exist, the decision to use an EA here was down to this transparency and
the ease with which to implement biological operators that are both meaningful
and easily understood.

The Evolutionary Dataset Optimisation method is dependent on a number of
parameters set out in this work one of which is the choice of distribution
families, \(\mathcal{P}\); these families go on to define the general
statistical shape of the columns of the datasets that are produced and also
control the present data types. The relationship between columns and their
associated distribution is not causal and appropriate methods should be employed
to understand the structure and characteristics of the data produced before
formal conclusions are made as set out in the case study provided.

It is known that EAs might terminate at a local optimum and may not be able to
traverse the entire sample space~\cite{Vikhar2016}, or even a sufficient part of
it. This would be even more problematic in the case presented in this work where
the sample space is not even of a fixed size or data type. In all experiments
carried out for this work, this theoretic limitation has not arisen.
Figure~\ref{fig:coverage} shows an exploration of the sample space and it is
evident that the EDO method was able to explore a large proportion of it. In the
early stages, it is also clear here how the EA got stuck in small parts of the
search space before later moving toward a subregion of the unit square.

\begin{figure}[htbp]
    \includegraphics[width=\imgwidth]{coverage.pdf}
    \caption{%
        A scatter and density plot of the selected parents at 10 epoch intervals
        from the last example of Section~\ref{subsec:dbscan}
    }\label{fig:coverage}
\end{figure}

Although this does provide evidence to say that the current design of the EA can
sufficiently explore its given search space, it does not provide any guarantee
that this will happen, even in expectation. Proving this theoretically is an
area for further investigation.

Something that does stand against EAs is their tendency to find the `easy' way
out. That is, reducing down to the simplest solution which solves the given
problem. In most cases, that is not a problem and is often, in fact, favourable.
Throughout the case study provided, this is seen to happen.
Figure~\ref{fig:coverage} shows this behaviour again by the strong diagonal
region in later generations. In that particular example, the easiest solution
for the EA (i.e.\ for \(k\)-means to outperform DBSCAN) was to collapse one
dimension of the search space to make the problem one-dimensional. This kind of
behaviour is not necessarily a bad thing as trivial, basic and simple cases are
of great importance when understanding an algorithm's quality.

However, should that be a problem, then the objective function could be adjusted
accordingly. In the case study, several iterations of fitness functions were
examined but each was adjusted by hand according to what was apparent at the
time. Due to the architecture of the implementation of this method, this could
be done in practicality. For instance, a similar strategy could be employed
automatically by a more sophisticated fitness function that retains some
information about the datasets generated from previous runs of EDO on a
particular (or at least similar) parameter set. In this way, the currently
completely unsupervised learning conducted by the EA could be ushered away from
less helpful solutions (via some penalty, say) and toward previously unexplored
behaviours. This automatic, iterative application of the proposed method would
likely reveal more sophisticated insights into a particular algorithm.

In essence, the proposed method is merely a tool that demonstrates the benefit
of the flipped paradigm set out in this work. The concept of where `good'
datasets exist is not something that is well-documented in literature and the
hope of this work is that Evolutionary Dataset Optimisation acts as a starting
point for further works to come.
