\chapter{Segmentation and the recovery of queuing parameters}
\label{chp:copd}

\graphicspath{{chapters/copd/paper/img/}}
\renewcommand{\texpath}{chapters/copd/paper/tex}

\begin{center}
    The research reported in this chapter has led to a manuscript
    entitled:\\[1em]

    {%
        \bf\itshape{``Segmentation analysis and the recovery of queuing
                    parameters via the Wasserstein distance: a study of
                    administrative data for patients with chronic obstructive
                    pulmonary disease''}
    }

    Available online at: \arxiv{2008.04295}\\
    Associated data: \doi{10.5281/zenodo.3924715}\\
    Source code: \doi{10.5281/zenodo.3936479}\\[2em]

    The abstract of the manuscript is as follows:\\[1em]
\end{center}

This work uses a data-driven approach to analyse how the resource requirements
of patients with chronic obstructive pulmonary disease (COPD) may change,
quantifying how those changes impact the hospital system with which the patients
interact. This approach is composed of a novel combination of often distinct
modes of analysis: segmentation, operational queuing theory, and the recovery of
parameters from incomplete data. By combining these methods as presented here,
this work demonstrates that potential limitations around the availability of
fine-grained data can be overcome. Thus, finding useful operational results
despite using only administrative data.

The paper begins by finding a useful clustering of the population from this
granular data that feeds into a multi-class \(M/M/c\) model, whose parameters
are recovered from the data via parameterisation and the Wasserstein distance.
This model is then used to conduct an informative analysis of the underlying
queuing system and the needs of the population under study through several
what-if scenarios.

The analyses used to form and study this model consider, in effect, all types of
patient arrivals and how those types impact the system. With that, this study
finds that there are no quick solutions to reduce the impact of COPD patients on
the system, including adding capacity to the system. In this analysis, the only
effective intervention to reduce the strain caused by those presenting with COPD
is to enact external policies which directly improve the overall health of the
COPD population before they arrive at the hospital.

\myrule%

This chapter differs from the manuscript by expanding the literature review into
Chapter~\ref{chp:lit}, providing a detailed discussion of the clustering
algorithm in Section~\ref{sec:intro}, and using an improved parameterisation for
the model in Sections~\ref{sec:model}~and~\ref{sec:scenarios}.

\section{Introduction}\label{sec:intro}

Appendix~\ref{app:data} carries out an exploratory analysis of a large,
administrative, healthcare dataset, revealing the presence of high variation in
the population. This variability stifles the possibility of uncovering valuable
insights about the whole population. However, there are some benefits are made
apparent by considering a condition-specific population. This chapter utilises
another administrative dataset of patients presenting chronic obstructive
pulmonary disease (COPD), and demonstrates how actionable insights can be
identified by thoroughly extracting information from the dataset.

Population health research is increasingly based on data-driven methods (as
opposed to those designed solely by clinical experts) for patient-centred care
through the advent of accessible software and a relative abundance of electronic
data. However, many such methods rely heavily on detailed data — about both the
healthcare system and its population — which may limit research where
sophisticated data pipelines are not yet in place.

This chapter demonstrates a method of overcoming this, using routinely gathered,
administrative hospital data to build a clustering that feeds into a multi-class
queuing model, allowing for better understanding of the healthcare population
and the system with which they interact. COPD is a condition of particular
interest to population health research, and to Cwm Taf Morgannwg UHB, as it is
known to often present as a comorbidity in patients~\cite{Houben2019},
increasing the complexity of treatments among those with the condition.
Moreover, an internal report by NHS Wales found the Cwm Taf Morgannwg UHB had
the highest prevalence of the condition across all the Welsh health boards.

The research in this chapter draws upon several overlapping sources within
mathematical research, and this chapter contributes to the literature in three
ways: to theoretical queuing research by the estimation of missing queuing
parameters with the Wasserstein distance; to operational healthcare research
through the weaving together of the combination of methods used in this chapter
despite data constraints; and to public health research by adding to the growing
body of mathematical and operational work around a condition that is vital to
understand operationally, socially and medically.

The chapter is structured as follows:

\begin{itemize}
    \item Section~\ref{sec:intro} provides an overview of the dataset and its
        clustering;
    \item Section~\ref{sec:queuing} offers a concise introduction to queuing
        theory;
    \item Section~\ref{sec:model} describes the queuing model used and the
        estimation of its parameters;
    \item Section~\ref{sec:scenarios} presents several what-if scenarios with
        insight provided by the model parameterisation and the clustering;
    \item Section~\ref{sec:summary} summarises the chapter.
\end{itemize}


\subsection{Overview of the dataset and its clustering}\label{subsec:overview}

The Cwm Taf Morgannwg UHB provided the dataset used in this chapter. The
dataset contains an administrative summary of 5,231 patients presenting COPD
from February 2011 through March 2019 totalling 10,861 spells. A patient
(hospital) spell is defined as the continuous stay of a patient using a hospital
bed on premises controlled by a healthcare provider and is made up of one or
more patient episodes~\cite{NHS:spell}. The following attributes describe the
spells included in the dataset:

\begin{itemize}
    \item Personal identifiers and information, i.e. patient and spell ID
        numbers, and identified gender;
    \item Admission/discharge dates and approximate times;
    \item Attributes summarising the clinical path of the spell including
        admission/discharge methods, and the number of episodes, consultants and
        wards in the spell;
    \item International Classification of Diseases (ICD) codes and primary
        Healthcare Resource Group (HRG) codes from each episode;
    \item Indicators for any COPD intervention. The value for any given instance
        in the dataset (i.e. a spell) is one of no intervention, pulmonary
        rehabilitation (PR), specialist nursing (SN), and both interventions;
    \item Charlson Comorbidity Index (CCI) contributions from several long term
        conditions (LTCs) as well as indicators for some other conditions such
        as sepsis and obesity. CCI is useful in anticipating hospital
        utilisation as a measure for the burdens associated with
        comorbidity~\cite{Simon2011};
    \item Rank under the 2019 Welsh Index of Multiple Deprivation (WIMD),
        indicating relative deprivation of the postcode area the patient lives
        in which is known to be linked to COPD prevalence and
        severity~\cite{Collins2018,Sexton2016,Steiner2017}.
\end{itemize}

In addition to the above, the following attributes were engineered for each
spell:

\begin{itemize}
    \item Age and spell cost data were linked to approximately half of the
        spells in the dataset from the administrative dataset analysed in
        Appendix~\ref{app:data};
    \item The presenting ICD codes were generalised to their categories
        according to NHS documentation and counts for each category were
        attached. This reduced the number of values from
        1,926 codes to 21 categories;
    \item A measure of admission frequency was calculated by taking the number
        of COPD-related admissions in the last twelve months linked to the
        associated patient ID number.
\end{itemize}

Although there is a fair amount of information here, it is limited to
COPD-related admissions. Therefore, rather than segmenting the patients
themselves, the spells will be. 

The attributes included in the clustering encompass both utilisation metrics and
clinical attributes relating to the spell. They comprise the summary clinical
path attributes, the CCI contributions and condition indicators, the WIMD rank,
length of stay (LOS), COPD intervention status, and the engineered attributes
(not including age and costs due to lack of coverage between the two datasets).

With these attributes selected, a clustering algorithm must be chosen. Two
critical specifications of the algorithm used are that it must handle mixed-type
data, and that it should be interpretable by stakeholders. As such, the
\(k\)-prototypes algorithm is a strong candidate. The \(k\)-prototypes algorithm
was mentioned in Chapter~\ref{chp:kmodes} and is a mixed-type extension to the
\(k\)-modes and \(k\)-means algorithms; in effect, the \(k\)-prototypes
algorithm separates the given dataset into its numeric and categorical
attributes before applying \(k\)-means and \(k\)-modes on the respective parts.
The statement of the \(k\)-prototypes algorithm has been omitted since it is
equivalent to that of \(k\)-modes (given in Algorithm~\ref{alg:kmodes}) with the
exceptions that:

\begin{itemize}
    \item The \textsc{SelectClosest} function uses the dissimilarity measure
        given in~\eqref{eq:dissim};
    \item The \textsc{Update} function is as given in
        Algorithm~\ref{alg:update}.
\end{itemize}

These parts are combined using a modified dissimilarity function, defined
in~\eqref{eq:kprototypes}. This function is a linear combination of the squared
Euclidean distance and the dissimilarity function defined in~\eqref{eq:dissim}
according to a single weight, \(\gamma \in \mathbb R\). The notation and
terminology for clustering mixed-type data is much the same as in
Chapter~\ref{chp:kmodes}. However, there are substantial differences: first,
representative points are referred to as \emph{prototypes}; and, second, an
attribute space \(\mathcal A\) of \(m\) mixed-type attributes can be written as
the product of its numeric and categorical components:

\begin{equation}
    \mathcal A
    = \prod_{j=1}^{p} A^{(n)}_j \times \prod_{j=p+1}^{m} A^{(c)}_j
    = \mathcal A^{(n)} \times \mathcal A^{(c)}
\end{equation}

Here, \(A^{(n)}\) and \(A^{(c)}\) denote individual numeric and categorical
attributes, respectively. Meanwhile, \(\mathcal A^{(n)}\) and \(\mathcal
A^{(c)}\) denote the numeric and categorical components of the space. With this
notation, the dissimilarity between two points, \(X, Y \in \mathcal A\), is
defined to be:

\begin{equation}\label{eq:kprototypes}
    d(X, Y) = \sum_{j=1}^{p} \left(x_j - y_j\right)^2 + \gamma \sum_{j=p+1}^{m}
    \delta \left(x_j, y_j\right)
\end{equation}

\input{chapters/copd/paper/tex/kprototypes}

In addition to this dissimilarity function, \(k\)-prototypes has a cost function
that uses the same linear combination as its dissimilarity function to consider
the numeric and categorical attributes. This function combines the categorical
cost function (defined in~\eqref{eq:cost}) and inertia (defined
in~\eqref{eq:inertia}) according to the same value of \(\gamma\). A proof that
minimising this linear combination also minimises the intra-cluster
\(k\)-prototypes dissimilarity is given in~\cite{Huang1997a}.

The choice of \(\gamma\) is of particular importance as it balances the
contribution of each data type to the objective function. The seminal work by
Huang~\cite{Huang1997a} investigated the effect of various \(\gamma\) values
when clustering with \(k\)-prototypes. This investigation determined that a
sensible and robust value for \(\gamma\) is the average of the standard
deviations for the numeric attributes. The analysis that informed the clustering
in this chapter found that this value for \(\gamma\) provided a useful
clustering; as such, no further modifications were made.

To determine the optimal number of clusters, \(k\), the same knee point
detection algorithm used at the end of Chapter~\ref{chp:kmodes} was used with a
range of potential values for \(k\) from two to ten. This range was chosen based
on what may be considered feasibly informative to stakeholders. Applying this
algorithm revealed an optimal value for \(k\) of four, but both three and five
clusters were considered. Both of these cases were eliminated due to a lack of
clear separation in the characteristics of the clusters.

Additionally, the initialisation method used for \(k\)-prototypes was the
matching initialisation presented in Chapter~\ref{chp:kmodes}. This
initialisation gave a slight improvement over Cao's method in terms of the
objective function.
% TODO Should there be more here? The improvement is *very* slight (even a
% rounding error to be honest) but this method has the scope for some ad-hoc
% matching -- is that worth mentioning?

\begin{table}
    \centering
    \resizebox{\textwidth}{!}{%
        \input{\texpath/summary.tex}
    }\caption{%
        A summary of clinical and condition-specific characteristics for each
        cluster and the population
    }\label{tab:summary}
\end{table}

Although the dataset is confidential and may not be published, a synthetic
analogue which illustrates the clustering has been archived
under~\doi{10.5281/zenodo.3908167}. A summary of the dataset and its clustering
is provided in Table~\ref{tab:summary}. Note that a negative length of stay
indicates that the patient had passed away prior to arriving at the hospital and
so these spells have been omitted from further analysis. This table separates
each cluster and the overall dataset (referred to as the population). From this
table, helpful insights can be gained about the segments identified by the
clustering. For instance, the needs of the spells in each cluster can be
summarised succinctly:

\begin{itemize}
    \item Cluster 0 represents those spells with relatively {\slshape low
        clinical complexity but high resource requirements}. The mean spell cost
        is almost four times the population average, and the shortest spell is
        almost two weeks long. Moreover, the median number of COPD-related
        admissions in the last year is elevated, indicating that patients
        presenting in this way require more interactions with the system.
    \item Cluster 1, the second-largest segment, represents the spells with
        {\slshape complex clinical profiles despite lower resource
        requirements}. Specifically, the spells in this cluster have the highest
        median CCI and number of LTCs, and the highest condition prevalence
        across all clusters but the second-lowest length of stay and spell
        costs.
    \item Cluster 2 represents the majority of spells and those where {\slshape
        resource requirements and clinical complexities are minimal}; these
        spells have the shortest lengths, and the patients present with fewer
        diagnoses and a lower median CCI than any other cluster. In addition to
        this, the spells in Cluster 2 have the highest intervention prevalence.
        However, they have the lowest condition prevalence across all clusters.
    \item Cluster 3 represents the smallest section of the population but
        perhaps the most critical: spells with {\slshape high complexity and
        high resource needs.} The patients within Cluster 3 are the oldest in
        the population and are some of the most frequently returning despite
        having the lowest intervention rates. The lengths of stay vary between
        seven and 32 weeks, and the mean spell cost is almost eight times the
        population average. This cluster also has the second-highest median
        CCI, and the highest median number of concurrent diagnoses.
\end{itemize}

The attributes listed in Table~\ref{tab:summary} can be studied beyond summaries
such as these, however. Figures~\ref{fig:los}~through~\ref{fig:icds} show the
distributions for some clinical characteristics for each cluster. Each of these
figures also shows the distribution of the same attributes when splitting the
population by intervention. While this classical approach --- of splitting a
population based on a condition or treatment --- can provide some insight into
how the different interventions are used, it has been included to highlight the
value added by segmenting the population via data without such a prescriptive
framework.

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{cluster_true_los}
        \caption{}\label{fig:cluster_los}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{intervention_true_los}
        \caption{}\label{fig:intervention_los}
    \end{subfigure}
    \caption{%
        Histograms for length of stay by (\subref{fig:cluster_los}) cluster and
        (\subref{fig:intervention_los}) intervention
    }\label{fig:los}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{cluster_spell_cost}
        \caption{}\label{fig:cluster_cost}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{intervention_spell_cost}
        \caption{}\label{fig:intervention_cost}
    \end{subfigure}
    \caption{%
        Histograms for spell cost by (\subref{fig:cluster_cost}) cluster and
        (\subref{fig:intervention_cost}) intervention
    }\label{fig:cost}
\end{figure}

Figure~\ref{fig:los} shows the length of stay distributions as histograms.
Figure~\ref{fig:cluster_los} demonstrates the different bed resource
requirements well for each cluster --- better than Table~\ref{tab:summary} might
--- in that the difference between the clusters is not only a matter of varying
means and ranges, but entirely different shapes to their respective
distributions. Indeed, they are all positively skewed, but there is no real
consistency beyond that. When comparing this to
Figure~\ref{fig:intervention_los}, there is undoubtedly some variety, but the
overall shapes of the distributions are generally similar. The exception is the
spells with no COPD intervention where binning could not improve the
visualisation due to the widespread distribution of their lengths of stay.

The same conclusions can be drawn about spell costs from Figure~\ref{fig:cost};
there are distinct patterns between the clusters in terms of their costs, and
they align with the patterns seen in Figure~\ref{fig:los}. Such patterns are
expected given that length of stay is a driving force of healthcare costs.
Equally, there does not appear to be any immediately discernible difference in
the distribution of costs when splitting by intervention.

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{cluster_charlson_gross}
        \caption{}\label{fig:cluster_charlson}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{intervention_charlson_gross}
        \caption{}\label{fig:intervention_charlson}
    \end{subfigure}
    \caption{%
        Histograms for CCI by (\subref{fig:cluster_charlson}) cluster and
        (\subref{fig:intervention_charlson}) intervention
    }\label{fig:charlson}
\end{figure}

Similarly to the previous figures, Figure~\ref{fig:charlson} shows that
clustering has revealed distinct patterns in the CCI of the spells within each
cluster, whereas splitting by intervention does not. All clusters other than
Cluster 2 show clear, heavy tails, and in the cases of Clusters 1 and 3, the
body of the data exists far from the origin as indicated in
Table~\ref{tab:summary}. In contrast, the plots in
Figure~\ref{fig:intervention_charlson} all display similar, highly skewed
distributions regardless of intervention.

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{cluster_ltcs}
        \caption{}\label{fig:cluster_ltcs}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{intervention_ltcs}
        \caption{}\label{fig:intervention_ltcs}
    \end{subfigure}
    \caption{%
        Proportions of the number of concurrent LTCs in a spell by
        (\subref{fig:cluster_ltcs}) cluster and (\subref{fig:intervention_ltcs})
        intervention
    }\label{fig:ltcs}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{cluster_icds}
        \caption{}\label{fig:cluster_icds}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{intervention_icds}
        \caption{}\label{fig:intervention_icds}
    \end{subfigure}
    \caption{%
        Proportions of the number of concurrent ICDs in a spell by
        (\subref{fig:cluster_icds}) cluster and (\subref{fig:intervention_icds})
        intervention
    }\label{fig:icds}
\end{figure}

Figures~\ref{fig:ltcs}~and~\ref{fig:icds} show the proportions of each grouping
presenting levels of concurrent LTCs and ICDs, respectively. By exposing the
distribution of these attributes, some notion of the clinical complexity for
each cluster can be captured better than with Table~\ref{tab:summary} alone. In
Figure~\ref{fig:cluster_ltcs}, for instance, there are distinct LTC count
profiles among the clusters: Cluster 0 is typical of the population; Cluster 1
shows that no patient presented COPD solely as an LTC in their spells, and more
than half presented at least three; Cluster 2 is similar in form to the
population but is severely biased towards patients presenting COPD as the only
LTC; Cluster 3 is the most uniformly spread among the four bins despite the
increased length of stay and CCI suggesting a diverse array of patients in
terms of their long term medical needs.

Figure~\ref{fig:cluster_icds} largely mirrors these cluster profiles with the
number of concurrent ICDs. Some points of interest, however, are that Cluster 1
has a relatively low-leaning distribution of ICDs that does not marry up with
the high rates of LTCs, and that the vast majority of spells in Cluster 3
present with at least nine ICDs suggesting a likely wide range of conditions and
comorbidities beyond the LTCs used to calculate CCI.\

However, little can be drawn from the intervention counterparts to these figures
(i.e. Figures~\ref{fig:intervention_ltcs}~and~\ref{fig:intervention_icds}),
regarding the corresponding spells. One thing of note is that patients receiving
both interventions for their COPD (or either, in fact) have disproportionately
fewer LTCs and concurrent ICDs when compared to the population. Aside from this,
the profiles of each intervention are similar to one another.

As discussed earlier, the purpose of this chapter is to construct a queuing
model for the data described here. Insights have already been gained into the
needs of the segments that have been identified in this section. However, to
glean further insights, some parameters of the queuing model must be recovered
from the data. The following two sections briefly introduce queues, and describe
how these parameters are derived using the dataset at hand, respectively.


\section{An introduction to queues}\label{sec:queuing}

Queues facilitate the orderly provision of services. Examples include lining up
to board a bus, assembly lines in a factory, or patients arriving at a hospital.
In all queues there are two types of agent: those providing the
service (a bus driver), and those demanding it (the passengers). The generic
terminology for these agents are \emph{servers} and \emph{customers},
respectively.

As well as individual queues, networks of interconnecting queues can be
described in a similar manner. In a \emph{queuing network}, each individual
queue is called a \emph{node}. For instance, a hospital could be considered a
network of queues, where patients arrive into triage, are processed, and are
redirected throughout their spell.

The observed characteristics of a queuing system can be used to construct a
mathematical model. Such a model would describe things like the process by which
customers arrive to a queue, the rules that allow customers to be served, and
the time taken to serve a customer. Queuing theory is the branch of mathematics
concerned with the analysis of these models.

The remainder of this section defines some of the fundamental elements necessary
to discuss the queues used in this chapter. This section omits many aspects of
queuing theory that would typically be covered in an introductory course on the
subject. Queuing theory is a mature discipline with many facets that extend
beyond the needs of this chapter, and the scope of this thesis. Comprehensive
and informative introductions to queuing models, queuing theory, and the
simulating of queues can be found in~\cite{Bhat2015,Shortle2018,Stewart2009}.
Further, applications of queuing models to healthcare systems are plentiful, but
examples include~\cite{%
    Bittencourt2018,Cochran2009,Mohammadi2012,Steins2013,Williams2015,Yom2014%
}.

\subsection{Elements of a queue}\label{subsec:elements}

A queue is made up several components: the service facility, a number of servers
within that facility, a line in which customers wait to be served, and a stream
of arriving customers. Figure~\ref{fig:queue} shows a diagram of a queue. The
characteristics associated with the components of a queue are often summarised
using Kendall's notation~\cite{Stewart2009}. The exact notation varies somewhat,
but here it shall be denoted \(A/S/c/m/K/Q\). This notation also defines the
\emph{parameters} of the queue. The process in Section~\ref{sec:model} estimates
some unknown parameters of a queue.

\begin{figure}[htbp]
    \centering%
    \resizebox{\imgwidth}{!}{%
        \input{chapters/copd/tex/queue}
    }\caption{The anatomy of a queue}\label{fig:queue}
\end{figure}

Kendall's notation acts as a shorthand to fully describe a queue, and is as
follows. Customers arrive to the queue according to an \emph{inter-arrival time
distribution}, \(A\), and wait in line to be served according to a \emph{queuing
discipline}, \(Q\). Typically, customers are served as they arrive. This
discipline is called FIFO (first in first out). Other disciplines include LIFO
(last in first out) and priority scheduling --- as used in emergency triage. At
the service facility there are \(c\) parallel servers, who each serve customers
according to the \emph{service time distribution}, \(S\). Sometimes it is
beneficial to attach a capacity to the system, denoted by \(K \ge c\). If
omitted, an unlimited system capacity is presumed. The \emph{system capacity}
can also be distinguished from an optional \emph{queue capacity}, \(m < K\),
which limits the number of customers allowed to wait in line. Again, this is
assumed to be \(\infty\), unless specified.

The distributions used to model inter-arrival and service times are numerous,
but some commonly studied examples are:

\begin{itemize}
    \item Markovian (denoted \(M\)). Customers arrive according to a Poisson
        process. The inter-arrival or service times follow an exponential
        distribution with rate \(\alpha > 0\), i.e. they have probability
        density function:
        \begin{equation}\label{eq:exponential}
            f(t) = \alpha e^{-\alpha t}; \quad t \ge 0
        \end{equation}
    \item Deterministic (denoted \(D\)). Inter-arrival or service times are
        non-stochastic and are of fixed length.
    \item General (denoted \(G\)). Arrivals are random, and inter-arrival or
        service times follow a general probability distribution.
\end{itemize}

\subsection{Some well-known queues}\label{subsec:known}

\subsubsection{The \(M/M/1\) queue}

One of the best-known queues is the \(M/M/1\) queue. In this queue, customers
arrive according to a Poisson process at a rate, \(\lambda\). The customers are
served by a single server exponentially, at a rate of \(\mu\). Owing to the
memoryless property of the exponential distribution, this queue can be
represented as a continuous-time Markov chain over the state space
\(\mathbb{N}_0 = \left\{0, 1, 2, \ldots\right\}\).

A stochastic process, \(\left(X_t\right)\), which is defined over a countable
state space, \(\mathcal S\), is considered a \emph{Markov chain} if and only if
for all \(n \in \mathbb N\) and for any \((n+1)\)-tuple of states, \(s_0,
\ldots, s_n \in \mathcal S^n\), the process satisfies:

\begin{equation}
    \mathbb P \left(X_n = s_n \ | \ X_{n-1} = s_{n-1}, \ldots, X_0 = s_0\right)
    = \mathbb P \left(X_n = s_n \ | \ X_{n-1} = s_{n-1}\right)
\end{equation}

That is, the probability of being in state \(s_n\) is dependent only on the
previous state, \(s_{n-1}\). The Markov chain underlying the \(M/M/1\) is also
known as a \emph{birth-death process}. Figure~\ref{fig:birth_death_mm1} shows a
diagram of the birth-death process of an \(M/M/1\) queue.

\begin{figure}[htbp]
    \centering
    \resizebox{\imgwidth}{!}{%
        \input{chapters/copd/tex/birth_death_mm1}
    }\caption{
        A state space diagram for an \(M/M/1\) queue%
    }\label{fig:birth_death_mm1}
\end{figure}

An important property of the \(M/M/1\) queue is its \emph{traffic intensity},
which is defined as \(\rho = \frac{\lambda}{\mu}\). This quantity also
represents the proportion of time that the server spends serving customers, and
so measures their \emph{utilisation}. The \(M/M/1\) queue is considered
\emph{stable} (i.e. the underlying process will become stationary eventually) if
\(\rho < 1\). In an unstable queue, customers arrive at a faster rate than they
are served, and so the line grows indefinitely.

Many other properties of the \(M/M/1\) queue can be explicitly derived from this
representation, including steady-state solutions, the expected size of the
system, and average response times. The calculation of these quantities also
makes use of Little's Law~\cite{Little1961}, which relates average system size,
\(L\), with average waiting time, \(W\), in stationary processes such that:
\begin{equation}
    L = \lambda W
\end{equation}

\subsubsection{The \(M/M/c\) queue}

The \(M/M/c\) queue is an extension of the \(M/M/1\) queue where there are \(c
\in \mathbb N\) independent servers working in parallel. Customers still arrive
according to a Poisson process with rate, \(\lambda\), and customer service
times follow an exponential distribution with a mean of \(\frac{1}{\mu}\). The
traffic intensity of the \(M/M/c\) queue is also \(\rho = \frac{\lambda}{\mu}\),
but server utilisation is measured as the mean traffic intensity across the
servers, i.e.  \(\frac{\rho}{c}\). The stability condition for the \(M/M/c\)
queue is \(\rho < c\). 

As with the \(M/M/1\) queue, the \(M/M/c\) can be represented as a birth-death
process on the state space \(\mathbb N_0\), as shown in
Figure~\ref{fig:birth_death_mmc}. Since there are multiple servers, some servers
may be idle when there are customers in the system. Once all servers are active,
arriving customers join the line and wait for service. 

\begin{figure}[htbp]
    \centering
    \resizebox{\imgwidth}{!}{%
        \input{chapters/copd/tex/birth_death_mmc}
    }\caption{
        A state space diagram for an \(M/M/c\) queue%
    }\label{fig:birth_death_mmc}
\end{figure}

\subsubsection{The \(M/G/c\) queue}

As useful as memoryless service times are in deriving properties of queues, they
are not always accurate to real systems. The \(M/G/c\) queue extends the
\(M/M/c\) queue to allow for a general service time distribution. Again, there
are \(c\) parallel servers and customers arrive randomly at a rate of
\(\lambda\).

The \(M/G/c\) queue cannot be represented as a Markov chain, but it is a
stochastic process on the same state space as the other queues in this section.
Given the generic nature of customer departure times, a lot of the structure of
the underlying process is lost. As such, deriving exact values for many
properties of the \(M/G/c\) queue continues to be an open
problem~\cite{Kingman2009}. Despite the theoretical challenges posed by the
\(M/G/c\), simulating these generic queues can still be of great benefit --- as
is done in Section~\ref{sec:model}. 

\subsection{Simulation tools}\label{subsec:tools}

As well as theoretical results, queues provide a valuable basis for computer
simulation. Theoretical models are limited when studying complex queuing
systems, where the parameterisation of a system requires complicated notation or
derivations to produce useful results. When properly utilising computer
simulation, the stochastic intricacies of a system may be more readily observed.
Examples of such systems include the multi-class queuing networks studied
in~\cite{Cochran2009}.

There are numerous tools available for simulating queues, but many leave the
associated research prone to issues like reproducibility --- as mentioned in
Section~\ref{subsec:queuing}. A recent review on the subject and its tools
is~\cite{Dagkakis2016}. One of the defining features of a simulation tool is
whether it has a \emph{graphical user interface} (GUI) or not. GUIs provide
accessibility to the non-technical members of a simulation project, but can also
foster poor simulation practices~\cite{Bell1987}.

The simulation framework of choice in this chapter is the discrete event
simulation library, Ciw~\cite{Palmer2019}. Ciw is written in Python, and is a
well-developed piece of open-source software, adhering to the same best
practices as the other software packages developed during this project.
In~\cite{Palmer2019}, the authors stress how ensuring sustainable and
reproducible simulation work are at the core of their development process.


\section{Constructing the queuing model}\label{sec:model}

The data available in this chapter is not as detailed as in comparative
projects, limiting the options for how a queuing model may be constructed.
Without access to such data --- but intending to gain insight from what is
available --- it is imperative to bridge the gap left by the incomplete data.
Figure~\ref{fig:process} provides a diagrammatic depiction of the process
described in this section.

It is often the case that in practical situations where suitable data is not
(immediately) available, further inquiry in that line of research will stop.
Queuing models in healthcare settings appear to be such a case; the line ends at
incomplete queue data. The bibliographic work~\cite{Asanjarani2017} collates
articles on the estimation of queuing system characteristics --- including their
parameters. Despite its breadth of almost 300 publications from 1955, only two
articles have been identified as being applied to
healthcare:~\cite{Mohammadi2012,Yom2014}. Both works are concerned with
customers who can re-enter services during their time in the queuing system,
which is mainly of value when considering the effect of unpredictable behaviour
in intensive care units, for instance. In~\cite{Mohammadi2012}, the authors seek
to approximate service and re-service densities through a Bayesian approach and
by filtering out those customers seeking to be serviced again. Meanwhile, the
approach in~\cite{Yom2014} considers an extension to the \(M/M/c\) queue with
direct re-entries. The devised model is then used to determine resource
requirements in two healthcare settings.

Aside from healthcare-specific works, the approximation of queue parameters has
formed a part of relevant modern queuing research. However, the scope is
primarily focused on theoretic approximations rather than by simulation. For
instance, two recent works~\cite{Djabali2018,Goldenshluger2016} consider an
underlying process to estimate a general service time distribution in single
server and infinite server queues respectively.

While these solutions are interesting, they do not necessarily tackle the issue
in this scenario where information about the system is also missing. With that,
there is a precedent for simplifying healthcare systems to a single node with
parallel servers that emulate overall resource availability. Two
studies~\cite{Steins2013,Williams2015} provide examples of how this approach,
when paired with discrete event simulation, can expose the resource needs of a
system beyond deterministic queuing theory models. In particular, the authors
of~\cite{Williams2015} show how a single node, multiple server queue can be used
to accurately predict bed capacity and length of stay distributions in a
critical care unit using administrative data.

\begin{figure}
    \centering%
    \resizebox{!}{.9\textheight}{%
        \input{chapters/copd/paper/tex/process_vertical.tex}
    }
    \caption{%
        A diagrammatic depiction of the queuing parameter recovery process
    }\label{fig:process}
\end{figure}


\subsection{Deriving the model parameters}\label{subsec:derive}

Following in the suit of recent literature~\cite{Steins2013,Williams2015}, this
chapter employs a single node using the \(M/M/c\) queue to model a hypothetical
ward of patients presenting COPD.\ In addition to this, the grouping found in
Section~\ref{subsec:overview} provides a set of patient classes in the queue.
Under this model, the following assumptions are made:

\begin{enumerate}
    \item Inter-arrival and service times of patients are each exponentially
        distributed with some mean. This distribution is used to simplify the
        model parameterisation.
    \item There are \(c \in \mathbb{N}\) servers available to arriving patients
        at the node representing the overall resource availability, including
        bed capacity and hospital staff.
    \item There is no queue or system capacity. In~\cite{Williams2015}, a
        queue capacity of zero is set under the assumption that any surplus
        arrivals would be sent to another suitable ward or unit. As this
        hypothetical ward represents the sole unit for COPD patients within the
        health board, this assumption is not held.
    \item Without the availability of expert clinical knowledge, a
        first-in-first-out service policy is employed in place of some patient
        priority framework.
\end{enumerate}

Each group of patients has its arrival distribution, the parameter of which is
the reciprocal of the mean inter-arrival times for that group. This parameter
is denoted by \(\lambda_l\) for each cluster \(l\).

Like arrivals, each group of patients has its service time distribution.
Without full details of the process order or idle periods during a spell, some
assumption must be made about the actual `service' time of a patient in the
hospital. It is assumed here that the mean service time of a group of patients
may be approximated via their mean length of stay, i.e. the mean time spent in
the system. As indicated by the distributions in Figure~\ref{fig:cluster_los},
the length of stay distributions require shifting prior to fitting an
exponential distribution.

Let \(T_l\) denote the set of observed lengths of stay for cluster \(l\), and
let \(m_l = \max \left\{0, \min T_l\right\}\) be its feasible minimum. Thus, the
\emph{shifted times} for cluster \(l\), denoted \(\widehat T_l\), are:

\begin{equation}\label{eq:shifted}
    \widehat T_l := \left\{t - m_l : t \in T_l\right\}
\end{equation}

An exponential distribution may be fitted to these shifted system times by
using their mean, denoted by \(\frac{1}{\phi_l}\), as the distribution
parameter. For the sake of simplicity, it is assumed that for each cluster
\(l\), the mean shifted service time of that cluster, \(\frac{1}{\mu_l}\), is
proportional to the corresponding mean shifted system time such that:

\begin{equation}\label{eq:shifted_services}
    \mu_l = p_l \phi_l
\end{equation}

\noindent where \(p_l \in \interval[open left]{0}{1}\) is a {\slshape service
proportion} parameter to be determined for each group.

With these definitions, the service time for cluster \(l\), denoted \(S_l\), is
distributed by a {\slshape shifted exponential distribution} with a mean of
\(\frac{1}{\mu_l}\) and shift of \(m_l\). The probability density function
of this distribution is as follows:

\begin{equation}\label{eq:shifted_pdf}
    f(s) = \begin{cases}
        \mu_l e^{-\mu_l (s - m_l)} & \quad \text{if \(s \ge m_l\)}\\
        0 & \quad \text{otherwise}
    \end{cases}
\end{equation}

Since this distribution is geometrically identical to the exponential
distribution with rate \(\mu_l\) except for a shift of \(m_l\), its memoryless
property holds for \(s \ge m_l\). However, since this model allows for multiple
classes and the shift terms are not the same for each cluster, this model
technically should be reclassified as a \(M/G/c\) model. Regardless of this, the
mean service time for spells in cluster \(l\) is given by:

\begin{equation}\label{eq:services}
    \mathbb E \left(S_l\right)
    = \int_{m_l}^{\infty} \mu_l s e^{-\mu_l (s - m_l)} \mathrm ds
    = m_l + \frac{1}{\mu_l}
\end{equation}

\subsection{Validating the model}\label{subsec:validate}

One of the few ground truths available in the provided data is the observed
length of stay distribution. Given that the length of stay and resource
availability are connected, the approach here will be to simulate the length of
stay distributions for a range of values \(p_l\) and \(c\), to find the
parameters that best match the observed data.

Several methods are available for the statistical comparison of two or more
distributions, such as the Kolmogorov-Smirnov test, a variety of discrepancy
approaches such as summed mean-squared error, and \(f\)-divergences. A popular
choice among the last group (which may be considered distance-like) is the
Kullback-Leibler divergence which measures relative information entropy from one
probability distribution to another~\cite{Kullback1951}. A key issue with many
of these methods is that they lack interpretability, something which is
paramount when conveying information to stakeholders, not only for explaining
how something works but also how its results may be explained.

As such, a reasonable candidate is the (first) Wasserstein metric, also known as
the `earth mover' or `digger' distance~\cite{Vaserstein1969}. The Wasserstein
metric satisfies the conditions of a formal mathematical metric (like the
typical Euclidean distance), and its values take the units of the distributions
under comparison (in this case: days). These characteristics can aid
understanding and explanation. The distance measures the approximate `minimal
work' required to move between two probability distributions where `work' can be
loosely defined as the product of how much of the distribution's mass moves and
the distance by which it must be moved. More formally, the Wasserstein distance
between two probability distributions \(U\) and \(V\) is defined as:

\begin{equation}\label{eq:wasserstein}
    W(U, V) = \int_{0}^{1} \left\vert F^{-1}(t) - G^{-1}(t) \right\vert dt
\end{equation}

Here, \(F\) and \(G\) are the cumulative density functions of \(U\) and \(V\),
respectively. A proof of~\eqref{eq:wasserstein} is presented
in~\cite{Ramdas2017}.

Each trial used here takes a parameter set and simulates the ward across a
series of independent repetitions. The parameter set with the smallest maximum
distance between the simulated system time distribution and the observed length
of stay distribution is taken to be the most appropriate. To be specific, let
\(T_{c,p}\) denote the system time distribution obtained from a simulation with
\(c\) servers and \(p := \left(p_0,p_1,p_2,p_3\right)\), and let \(T\) denote
the observed length of stay distribution. Then the optimal parameter set
\(\left(c^*, p^*\right)\) is given by:

\begin{equation}\label{eq:parameters}
    \left(c^*, p^*\right) = \argmin_{c, p} \left\{%
        \max \left\{ W\left(T_{c,p}, T\right) \right\}%
    \right\}
\end{equation}

The parameter sweep included values of each \(p_l\) from \(0.5\) to \(1.0\) with
a granularity of \(5.0 \times 10^{-2}\) and values of \(c\) from \(30\) to
\(50\) at steps of five. These choices were informed by the assumptions of the
model and formative analysis to reduce the parameter space given the
computational resources required to conduct the simulations. Each parameter set
was repeated 50 times with each simulation running for four years of virtual
time. The warm-up and cool-down periods were taken to be approximately one year
each leaving two years of simulated data from each repetition.

\begin{figure}
    \centering
    \includegraphics[width=\imgwidth]{best_params}
    \caption{%
        Histograms of the best-simulated and observed LOS data
    }\label{fig:best_params}
\end{figure}

\begin{figure}
    \includegraphics[width=\imgwidth]{median_params}
    \caption{%
        Histograms of the median-simulated and observed LOS data
    }\label{fig:median_params}
\end{figure}

\begin{figure}
    \includegraphics[width=\imgwidth]{worst_params}
    \caption{%
        Histograms of the worst-simulated and observed LOS data
    }\label{fig:worst_params}
\end{figure}

The results of this parameter sweep can be summarised in
Figures~\ref{fig:best_params}~through~\ref{fig:worst_params}. Each plot shows a
comparison of the observed lengths of stay across all groups and the newly
simulated data with the best, median and worst parameter sets, respectively.
These figures highlight the importance of choosing good parameters under this
model as the differences in the quality of the fits are stark. In the best case
the fit is uncanny, whereas the median case shows a distribution that inflates
the presence of short-stay patients despite an otherwise good fit. Meanwhile,
Figure~\ref{fig:worst_params} displays a distribution that only resembles the
observed distribution in its positive skew; the worst-case distribution lacks
the distinctive `exponential' nose and has a considerably heavier tail
corresponding to a disproportionate amount of long-stay patients.
Table~\ref{tab:comparison} reinforces these results numerically, showing a
precise fit by the best parameter set across all measures, except the maximum
recorded stay.

\begin{table}
    \centering
    \resizebox{\textwidth}{!}{%
        \input{\texpath/comparison.tex}
    }
    \caption{%
        A comparison of the observed and simulated data based on the model
        parameters and summary statistics for length of stay
    }\label{tab:comparison}
\end{table}

In this section, the previously identified clustering enriched the overall
queuing model and was used to recover the parameters for several classes within
that. Now, using this model, the next section details an investigation into the
underlying system by adjusting the parameters of the queue with the clustering.

\section{Adjusting the queuing model}\label{sec:scenarios}

This section comprises several what-if scenarios --- a classic component of
healthcare operational research --- under the novel parameterisation of the
queue established in Section~\ref{sec:model}. The outcomes of interest in this
work are server (resource) utilisation and system times. These metrics capture
the driving forces of cost and the state of the system. Specifically, the
objective of these experiments is to address the following questions:
\begin{itemize}
    \item How would the system be affected by a change in overall patient
        arrivals?
    \item How is the system affected by a change in resource availability?
    \item How is the system affected by patients moving between clusters?
\end{itemize}

Given the nature of the observed data, the queuing model parameterisation and
its assumptions, the effects on the chosen metrics in each scenario are in
relative terms with respect to the base case. The base case being those results
generated from the best parameter set recorded in Table~\ref{tab:comparison}. In
particular, the data from each scenario is scaled by the corresponding median
value in the base case, meaning that a metric having a value of 1 is `normal'.

As mentioned in Section~\ref{sec:intro}, the source code used throughout this
work is available has been archived online under~\doi{10.5281/zenodo.3936479}.
Also, the datasets generated from the simulations in this section, and the
parameter sweep, have been archived online~\doi{10.5281/zenodo.3924715}.
% TODO Archive new data and update these DOIs.


\subsection{Changes to overall patient arrivals}\label{subsec:arrivals}

Changes in overall patient arrivals to a queue reflect real-world scenarios
where some stimulus is improving (or worsening) the condition of the patient
population. Examples of stimuli could include an ageing population or
independent life events that lead to a change in deprivation, such as an
accident or job loss. Within this model, overall patient arrivals are altered
using a scaling factor denoted by \(\sigma > 0\). This scaling factor is applied
to the model by multiplying each cluster's arrival rate by \(\sigma\). That is,
for cluster \(l\), its new arrival rate, \(\hat\lambda_l\),
is given by:

\begin{equation}\label{eq:lambda}
    \hat\lambda_{l} = \sigma\lambda_l
\end{equation}

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{lambda_time}
        \caption{}\label{fig:lambda_time}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{lambda_util}
        \caption{}\label{fig:lambda_util}
    \end{subfigure}
    \caption{%
        Plots of \(\sigma\) against relative (\subref{fig:lambda_time})~system
        time and (\subref{fig:lambda_util})~server utilisation
    }\label{fig:lambda}
\end{figure}

Figure~\ref{fig:lambda} shows the effects of changing patient arrivals on
(\subref{fig:lambda_time})~relative system times and
(\subref{fig:lambda_util})~relative server utilisation for values of \(\sigma\)
from 0.5 to 2.0 at a precision of \(1.0 \times 10^{-2}\). Specifically, each
plot in the figure (and the subsequent figures in this section) shows the median
and interquartile range (IQR) of each relative attribute. These metrics provide
an insight into the experience of a typical user (or server) in the system.
Furthermore, they reveal the stability and variation of the body of users
(or servers).

What is evident from these plots is that things are happening as one might
expect: as arrivals increase, the strain on the system increases. However, it
should be noted that it also appears that the model has some amount of slack
relative to the base case. Looking at Figure~\ref{fig:lambda_time}, for
instance, the relative system time distribution stays unchanged up to \(\sigma
\approx 1.3\), or an approximate 30\% increase in arrivals of COPD patients.
Beyond that, relative system times quickly rise to an untenable point where the
median time becomes orders of magnitude above the norm.

However, Figure~\ref{fig:lambda_util} shows that the situation for the system's
resources reaches its worst-case near to the start of that spike in relative
system times (at \(\sigma \approx 1.4\)). That is, the median server utilisation
reaches a maximum (this corresponds to constant utilisation) at this point, and
the variation in server utilisation disappears entirely.


\subsection{Changes to resource availability}\label{subsec:resources}

As is discussed in Section~\ref{sec:model}, the resource availability of the
system is captured by the number of parallel servers, \(c\). Therefore, to
modify the overall resource availability, only the number of servers needs to be
changed. This kind of sensitivity analysis is usually done to determine the
opportunity cost of adding service capacity to a system, e.g.\ would an increase
of \(n\) servers sufficiently increase efficiency without exceeding a budget?

To reiterate the beginning of this section: all suitable parameters are given in
relative terms, including the number of servers here. By doing this, the changes
in resource availability are more evident, and do away with any concerns as to
what a particular number of servers precisely reflects in the real world, be it
any combination of hospital beds, equipment availability and medical staff.

\begin{figure}
    \centering
    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{servers_time}
        \caption{}\label{fig:servers_time}
    \end{subfigure}

    \begin{subfigure}{\imgwidth}
        \includegraphics[width=\linewidth]{servers_util}
        \caption{}\label{fig:servers_util}
    \end{subfigure}
    \caption{%
        Plots of the relative number of servers against relative
        (\subref{fig:servers_time})~system time and
        (\subref{fig:servers_util})~server utilisation
    }\label{fig:servers}
\end{figure}

Figure~\ref{fig:servers} shows how the relative resource availability affects
relative system times and server utilisation. In this scenario, the relative
number of servers took values from 0.5 to 2.0 at an equivalent step size of one
in the number of servers, i.e. \(c\) takes values from 17 to 70. Overall, these
figures fortify the claim from the previous scenario that there is some room to
manoeuvre so that the system runs `as normal' but pressing on those boundaries
results in massive changes to both resource requirements and system times.

In Figure~\ref{fig:servers_time} this amounts to a maximum of 10\% slack in
resources before relative system times are substantially affected; further
reductions quickly result in a potentially tenfold increase in the median system
time, and up to 100 times once resource availability falls by 50\%. Moreover,
the variation in the body of the relative times (i.e. the IQR) decreases as
resource availability decreases. The reality of this is that patients arriving
at a hospital are forced to consume more significant amounts of resources (by
merely being in a hospital) regardless of their condition, putting added strains
on the system. Figure~\ref{fig:servers_util} mirrors these observations on the
small amount of slack in resource requirements, but (as with the previous
scenario) constant utilisation occurs quickly.

Meanwhile, it appears that there is no tangible change in relative system times
given an increase in the number of servers. This indicates that the model
carries sufficient resources to cater to the population under normal
circumstances and that adding service capacity will not necessarily improve
system times.

Again, Figure~\ref{fig:servers_util} shows that there is a substantial change in
the variation in the relative utilisation of the servers. In this case, the
variation dissipates as resource levels fall and increase as they increase.
While the relationship between real hospital resources and the number of servers
is not exact, having variation in server utilisation would suggest that small
parts of an existing system may be configured or partitioned away in the case of
some significant public health event (such as a global pandemic) without
overloading the system.


\subsection{Moving arrivals between clusters}\label{subsec:moving}

This scenario is perhaps the most relevant to actionable public health research
of those presented here. The clusters identified in this chapter could be
characterised by their clinical complexities and resource requirements, as done
in Section~\ref{subsec:overview}. Therefore, being able to model the movement of
some proportion of patient spells from one cluster to another will reveal how
those complexities and requirements affect the system itself. The reality is
then that if some public health policy could be implemented to enact that
movement informed by a model such as this, then real change would be seen in the
real system.

In order to model the effects of spells moving between two clusters, the
assumption is that each cluster's service time distribution stays the same (and
so does each cluster's \(p_l\)), but their arrival rates are altered according
to some transfer proportion. Consider two clusters indexed at \(l\) and \(m\),
and their respective arrival rates, \(\lambda_l\), \(\lambda_m\). Let \(\delta
\in [0, 1)\) denote the proportion of arrivals to be moved from cluster \(l\) to
cluster \(m\). Then the new arrival rates for each cluster, denoted by
\(\hat\lambda_l, \hat\lambda_m\) respectively, are:

\begin{equation}\label{eq:moving}
    \hat\lambda_l = \left(1 - \delta\right) \lambda_l
    \quad \text{and} \quad
    \hat\lambda_m = \delta\lambda_l + \lambda_m
\end{equation}

By moving patient arrivals between clusters in this way, the overall arrivals
are left the same since the sum of the arrival rates is the same. Hence, the
(relative) effect on server utilisation and system time can be measured
independently.

Figures~\ref{fig:moving_time}~and~\ref{fig:moving_util} show the effect of
moving patient arrivals between clusters on relative system time and relative
server utilisation, respectively. In each figure, the median and IQR for the
corresponding attribute is shown, as in the previous scenarios. Each scenario
was simulated using values of \(\delta\) from 0.0 to 0.98 at steps of \(2.0
\times 10^{-2}\).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{moving_time}
    \caption{%
        Plots of proportions of each cluster moving to another against relative
        system time
    }\label{fig:moving_time}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{moving_util}
    \caption{%
        Plots of proportions of each cluster moving to another on relative
        server utilisation
    }\label{fig:moving_util}
\end{figure}

Considering Figure~\ref{fig:moving_time}, it appears that each type of transfer
falls into one of two categories: either completely derailing the system (such
as moving any cluster to Cluster 3) or improving system times, albeit mildly. 
The latter case occurs in the following transfers:

\begin{itemize}
    \item Cluster 0 to Clusters 1 or 2
    \item Cluster 1 to Cluster 2
    \item Cluster 3 to any other cluster
\end{itemize}

A finer look at the effect of these transfer types on relative system times is
given in Table~\ref{tab:moving_time}. Likewise, their effects on relative server
utilisation is given in Table~\ref{tab:moving_util}. 

\begin{table}
    \centering%
    \resizebox{\textwidth}{!}{%
        \input{chapters/copd/paper/tex/moving_time.tex}
    }
    \caption{%
        Proportional changes in median relative system time for selected cluster
        transfers
    }\label{tab:moving_time}
\end{table}

\begin{table}
    \centering%
    \resizebox{\textwidth}{!}{%
        \input{chapters/copd/paper/tex/moving_util.tex}
    }
    \caption{%
        Proportional changes in median relative utilisation for selected cluster
        transfers
    }\label{tab:moving_util}
\end{table}

The message delivered by these transfers is that in order to improve system
times in hospitals, the only solution is for the patients arriving at hospital
to present with fewer resource requirements. Meanwhile, the complexity of their
condition is less influential. Achieving such reductions is certainly no mean
feat, but could be addressed by investing in more-advanced medical
infrastructure in other parts of the healthcare system, beyond hospitals.
Furthermore, this could be achieved by implementing some preventive policy that
would help improve the overall health of the COPD population, with particular
targeting for those most-affected by the condition.

Conversely, the concern arises when either of the low resource requirement
clusters moves to Cluster 0 or Cluster 3. Even as few as one in ten of the
low-complexity, low-resource-needs arrivals in Cluster 2 moving to either
cluster results in large jumps in the median system time for all arrivals. Soon
after, as in the previous scenario, any variation in the system times
disappears, indicating an overborne system.

With relative server utilisation, the story is much the same. The ordinary
levels of high-complexity, high-resource arrivals from Cluster 3 are absorbed by
the system and moving these arrivals to another cluster bears little effect on
resource consumption levels. Likewise, either of the low-resource needs clusters
moving even slightly toward high resource requirements completely overruns the
system’s resources. However, the relative utilisation levels of the system
resources can be substantially reduced by moving arrivals from Cluster 0 to
either Cluster 1 or Cluster 2, i.e. by reducing the overall resource
requirements of such spells.

In essence, this entire analysis offers two messages: that there are several
ways in which the system can get worse and even overwhelmed but, more
importantly, that any meaningful impact on the system must come from a stimulus
outside of the system that results in a higher proportion of healthy patients
arriving at the hospital. This conclusion is non-trivial; the first two
scenarios in this analysis show that there are no quick solutions to reduce the
effect of COPD patients on hospital capacity and length of stay. The only
effective intervention for improving the system on the whole is found through
inter-cluster transfers.


\section{Chapter summary}\label{sec:summary}

This chapter presents a novel approach to investigating a healthcare population
that encompasses the topics of segmentation analysis, queuing models, and the
recovery of queuing parameters from incomplete data. This investigation is done
despite characteristic limitations in operational research concerning the
availability of fine-grained data, and this chapter only uses administrative
hospital spell data from patients presenting COPD from the Cwm Taf Morgannwg
UHB.\

By considering a variety of attributes present in the data, and engineering
some, a useful clustering of the spell population is identified that
successfully feeds into a multi-class, \(M/M/c\) queue to model a hypothetical
COPD ward. With this model, several insights are gained by investigating
purposeful changes in the parameters of the model that have the potential to
inform actual public health policy.

In particular, since neither the resource capacity of the system nor the
clinical processes of the spells are evident in the data, service times and
resource levels are not available. However, the length of stay is. Using what is
available, this chapter assumes that mean service times can be parameterised
using mean lengths of stay. By using the Wasserstein distance to compare the
distribution of the simulated lengths of stay data with the observed data, a
best performing parameter set is found via a parameter sweep.

This parameterisation ultimately recovers a surrogate for service times for each
cluster, and a universal number of servers to emulate resource availability. The
parameterisation itself offers its strengths by being straightforward and
effective. Despite its simplicity, a good fit to the observed data is found,
and --- as is evident from the closing section of this chapter --- substantial
and useful insights can be gained into the needs of the population under study.

This mode of analysis, in effect, considers all types of patient arrivals and
how they each impact the system in terms of resource capacity and length of
stay. By investigating scenarios into changes in both overall patient arrivals
and resource capacity, it is clear that there is no quick solution to be
employed from within the hospital to improve COPD patient spells. The only
effective, non-trivial intervention is to improve the overall health of the
patients arriving at the hospital, as is shown by moving patient arrivals
between clusters. In reality, this would correspond to an external, preventive
policy that improves the overall health of COPD patients.
