\chapter{Conclusions}\label{chp:conc}

This chapter serves to summarise the work reported in this thesis, its
contributions to literature, and potential avenues for further work. Each
chapter in this thesis concluded with a detailed summary, and so the summaries
here are brief.

\section{Research summary}

Chapter~\ref{chp:intro} described the research questions associated with this
thesis, laying out its principle subjects of algorithm evaluation, clustering,
and operational healthcare modelling. With this last subject, there was a
particular interest in overcoming a common issue with machine learning
applications in healthcare: not necessarily having sufficiently detailed and
voluminous data with which to create meaningful, actionable models.

Chapter~\ref{chp:lit} presented a survey of the literature spanning these
principle topics and their intersections. Motivated by the apparent gaps in the
collated literature, the subsequent chapters of the thesis presented novel
methods for assessing the quality of an algorithm (or algorithms), and for
incorporating mathematical fairness into an existing clustering algorithm. These
methods later fed into the case study for \ctmuhb\ which characterised, analysed
and modelled a subsection of their patient population.

In Chapter~\ref{chp:edo}, a new paradigm by which algorithms may be assessed was
described, and a method from that paradigm presented. This method, known as
evolutionary dataset optimisation (EDO), explores the space in which `good'
datasets exist for an algorithm according to some metric. This exploration is
achieved via a bespoke evolutionary algorithm which acts on datasets of unfixed
shapes, sizes and data types. The chapter presented descriptions and
illustrations of the internal mechanisms of the EDO method, as well as briefly
describing a Python implementation. Finally, the chapter concluded with an
extensive case study, demonstrating the capabilities and nuances of EDO in
gaining a richer picture of an algorithm's abilities independently, and against
a competitor.

Following the discussion of `fair' machine learning practices in the literature
review, Chapter~\ref{chp:kmodes} offered a novel initialisation to the
\(k\)-modes algorithm which made use of game theory. The new initialisation
extended a commonly used method, but replaced its greedy component with a
solvable matching game. In the evaluative section of this chapter, traditional
assessment techniques suggested that the new method improved upon the original,
and so the original was discarded.

However, the new method did not consistently outperform another well-known
initialisation. To better understand the conditions under which either of the
remaining initialisations would succeed, a similar competitive setting to
Chapter~\ref{chp:edo} was used. This analysis revealed that there were distinct
sets of properties for which one method was more likely to succeed than the
other according to the metric under study.

Chapter~\ref{chp:copd} presented a novel framework with which to model the
resource needs of a condition-specific healthcare population --- despite a lack
of fine-grained data. In this case, that population were those suffering from
COPD. The corresponding dataset, provided by \ctmuhb, consisted of high-level,
administrative details about the spells associated with the patients, and lacked
the depth that many contemporary operational models require.

The presented framework utilised the clustering algorithm described in
Chapter~\ref{chp:kmodes} to segment a subset of existing and engineered
attributes in the dataset. These attributes included hospital utilisation
metrics, and proxy measures of clinical complexity and resource needs. The
segmentation successfully characterised the instances of the dataset, and the
ensuing analysis of the identified segments revealed clear profiles for each
segment. Included in these profiles were distinctly shaped distributions for
length of stay. With an aim to extract as much as possible from the available
data, and to provide further practical insights, these distributions were
utilised to construct a multi-class queuing model.

The queue, although minimal in structure, provided a well-fitting replica of the
true lengths of stay observed in the data. The quality of this model was
dependent on a novel parameterisation, which derived the unknown service time
distributions for each cluster from the data according to the Wasserstein
distance. In turn, this model was adjusted to answer several `what-if' scenarios
associated with changes in resource capacity and requirements for the population
under study. These adjustments revealed actionable insights into the
most-impactful segments of the population. The most important of these results
was demonstrating the futility of attempting to implement quick, blanket
solutions for that population, such as only increasing resource capacity without
improving patient well-being.

\section{Contributions}



\section{Further work}
